{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shujaat123/Ear_Biometrics/blob/main/Clean_Pytorch_Implementation_Ear_Biometric_for_AMI_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57mAz8uQMn9G",
        "outputId": "691afd3b-3abc-4842-eafb-432f243d177e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9656 sha256=2c5db59913c0f509bcffcc6b468d6513c0fbb12a95c846a5675c81ce2fa87ff6\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/f1/7f/5c94f0a7a505ca1c81cd1d9208ae2064675d97582078e6c769\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n",
            "Collecting py7zr\n",
            "  Downloading py7zr-0.20.6-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.7/66.7 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting texttable (from py7zr)\n",
            "  Downloading texttable-1.6.7-py2.py3-none-any.whl (10 kB)\n",
            "Collecting pycryptodomex>=3.6.6 (from py7zr)\n",
            "  Downloading pycryptodomex-3.18.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyzstd>=0.14.4 (from py7zr)\n",
            "  Downloading pyzstd-0.15.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (412 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m412.3/412.3 kB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyppmd<1.1.0,>=0.18.1 (from py7zr)\n",
            "  Downloading pyppmd-1.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.8/138.8 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pybcj>=0.6.0 (from py7zr)\n",
            "  Downloading pybcj-1.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.8/49.8 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multivolumefile>=0.2.3 (from py7zr)\n",
            "  Downloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\n",
            "Collecting brotli>=1.0.9 (from py7zr)\n",
            "  Downloading Brotli-1.0.9-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m92.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting inflate64>=0.3.1 (from py7zr)\n",
            "  Downloading inflate64-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (93 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from py7zr) (5.9.5)\n",
            "Installing collected packages: texttable, brotli, pyzstd, pyppmd, pycryptodomex, pybcj, multivolumefile, inflate64, py7zr\n",
            "Successfully installed brotli-1.0.9 inflate64-0.3.1 multivolumefile-0.2.3 py7zr-0.20.6 pybcj-1.0.1 pycryptodomex-3.18.0 pyppmd-1.0.0 pyzstd-0.15.9 texttable-1.6.7\n"
          ]
        }
      ],
      "source": [
        "## Load useful packages\n",
        "!pip install wget\n",
        "!pip install py7zr"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import py7zr\n",
        "from zipfile import ZipFile\n",
        "from random import sample\n",
        "import PIL.Image as Image\n",
        "import matplotlib.pyplot as plt\n",
        "from  sklearn.model_selection import train_test_split\n",
        "from os import listdir\n",
        "from os import path\n",
        "import h5py\n",
        "import numpy as np\n",
        "import wget\n",
        "from zipfile import ZipFile"
      ],
      "metadata": {
        "id": "WaA0QTb9MwPK"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LOADING AMI Dataset\n",
        "data_path = 'https://github.com/Shujaat123/Ear_Biometrics/blob/main/datasets/AMI_dataset.zip?raw=true'\n",
        "filename = 'AMI_dataset.zip'\n",
        "if(path.exists(filename)):\n",
        "  !rm $filename\n",
        "  print('existing file:', filename, ' has been deleted')\n",
        "print('downloading latest version of file:', filename)\n",
        "wget.download(data_path, filename)\n",
        "print('DONE')\n",
        "\n",
        "with ZipFile('AMI_dataset.zip', mode='r') as z:\n",
        "    z.extractall()\n",
        "!ls\n",
        "\n",
        "# Processing AMI_dataset\n",
        "src_dir = 'AMI_dataset'\n",
        "images_name = listdir(src_dir)\n",
        "images_name_temp = []\n",
        "subjects = []\n",
        "for img_ind in range(0,len(images_name)):\n",
        "  if(not(images_name[img_ind]=='Thumbs.db')):\n",
        "    subjects.append(int(images_name[img_ind].split('_')[0]))\n",
        "    images_name_temp.append(images_name[img_ind])\n",
        "\n",
        "images_name = images_name_temp\n",
        "images_name_ord = []\n",
        "subjects_ord = []\n",
        "\n",
        "sub_ind = sorted(range(len(subjects)),key=subjects.__getitem__)\n",
        "for pos, item in enumerate(sub_ind):\n",
        "  images_name_ord.append(images_name[item])\n",
        "  subjects_ord.append(subjects[item])\n",
        "\n",
        "images_name = images_name_ord\n",
        "subjects = subjects_ord\n",
        "\n",
        "print(subjects)\n",
        "##########--MODIFICATION to rearange missing labels #############\n",
        "subjects_temp = np.array(subjects)\n",
        "unique_ids=np.unique(np.array(subjects))\n",
        "\n",
        "for pos, item in enumerate(unique_ids):\n",
        "  subjects_temp[subjects==item] = pos+1\n",
        "\n",
        "subjects = list(subjects_temp)\n",
        "################################################################\n",
        "print(images_name)\n",
        "\n",
        "img_ind = 0\n",
        "ear_images = []\n",
        "sub_labels = [];\n",
        "target_size = (180, 50)\n",
        "\n",
        "for sub_ind in range(0,len(subjects)):\n",
        "  img_path = src_dir+'/'+images_name[sub_ind]\n",
        "  ear_img = (plt.imread(img_path))/255\n",
        "\n",
        "  ear_img = Image.open(img_path)\n",
        "  ear_img = ear_img.resize(target_size, Image.ANTIALIAS)\n",
        "  ear_img = np.asarray(ear_img).astype(np.float32)/255\n",
        "  ear_img = np.transpose(ear_img,(2,0,1))\n",
        "\n",
        "  ear_images.append(ear_img)\n",
        "  sub_labels.append(subjects[sub_ind]-1)\n",
        "\n",
        "ear_images = np.array(ear_images)\n",
        "sub_labels = np.array(sub_labels)\n",
        "\n",
        "print(ear_images.shape)\n",
        "print(sub_labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-gSS5XGlpPy",
        "outputId": "4d792ec2-4d97-4a54-f526-f6cbb6598294"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading latest version of file: AMI_dataset.zip\n",
            "DONE\n",
            "AMI_dataset  AMI_dataset.zip  sample_data\n",
            "[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 18, 18, 18, 18, 18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 20, 20, 20, 20, 20, 20, 20, 21, 21, 21, 21, 21, 21, 21, 22, 22, 22, 22, 22, 22, 22, 23, 23, 23, 23, 23, 23, 23, 24, 24, 24, 24, 24, 24, 24, 25, 25, 25, 25, 25, 25, 25, 26, 26, 26, 26, 26, 26, 26, 27, 27, 27, 27, 27, 27, 27, 28, 28, 28, 28, 28, 28, 28, 29, 29, 29, 29, 29, 29, 29, 30, 30, 30, 30, 30, 30, 30, 31, 31, 31, 31, 31, 31, 31, 32, 32, 32, 32, 32, 32, 32, 33, 33, 33, 33, 33, 33, 33, 34, 34, 34, 34, 34, 34, 34, 35, 35, 35, 35, 35, 35, 35, 36, 36, 36, 36, 36, 36, 36, 37, 37, 37, 37, 37, 37, 37, 38, 38, 38, 38, 38, 38, 38, 39, 39, 39, 39, 39, 39, 39, 40, 40, 40, 40, 40, 40, 40, 41, 41, 41, 41, 41, 41, 41, 42, 42, 42, 42, 42, 42, 42, 43, 43, 43, 43, 43, 43, 43, 44, 44, 44, 44, 44, 44, 44, 45, 45, 45, 45, 45, 45, 45, 46, 46, 46, 46, 46, 46, 46, 47, 47, 47, 47, 47, 47, 47, 48, 48, 48, 48, 48, 48, 48, 51, 51, 51, 51, 51, 51, 51, 52, 52, 52, 52, 52, 52, 52, 53, 53, 53, 53, 53, 53, 53, 54, 54, 54, 54, 54, 54, 54, 55, 55, 55, 55, 55, 55, 55, 56, 56, 56, 56, 56, 56, 56, 57, 57, 57, 57, 57, 57, 57, 58, 58, 58, 58, 58, 58, 58, 59, 59, 59, 59, 59, 59, 59, 61, 61, 61, 61, 61, 61, 61, 62, 62, 62, 62, 62, 62, 62, 63, 63, 63, 63, 63, 63, 63, 64, 64, 64, 64, 64, 64, 64, 65, 65, 65, 65, 65, 65, 65, 66, 66, 66, 66, 66, 66, 66, 67, 67, 67, 67, 67, 67, 67, 68, 68, 68, 68, 68, 68, 68, 69, 69, 69, 69, 69, 69, 69, 70, 70, 70, 70, 70, 70, 70, 71, 71, 71, 71, 71, 71, 71, 72, 72, 72, 72, 72, 72, 72, 73, 73, 73, 73, 73, 73, 73, 74, 74, 74, 74, 74, 74, 74, 75, 75, 75, 75, 75, 75, 75, 76, 76, 76, 76, 76, 76, 76, 77, 77, 77, 77, 77, 77, 77, 78, 78, 78, 78, 78, 78, 78, 79, 79, 79, 79, 79, 79, 79, 80, 80, 80, 80, 80, 80, 80, 81, 81, 81, 81, 81, 81, 81, 82, 82, 82, 82, 82, 82, 82, 83, 83, 83, 83, 83, 83, 83, 84, 84, 84, 84, 84, 84, 84, 85, 85, 85, 85, 85, 85, 85, 86, 86, 86, 86, 86, 86, 86, 87, 87, 87, 87, 87, 87, 87, 88, 88, 88, 88, 88, 88, 88, 89, 89, 89, 89, 89, 89, 89, 90, 90, 90, 90, 90, 90, 90, 91, 91, 91, 91, 91, 91, 91, 92, 92, 92, 92, 92, 92, 92, 93, 93, 93, 93, 93, 93, 93, 94, 94, 94, 94, 94, 94, 94, 95, 95, 95, 95, 95, 95, 95, 96, 96, 96, 96, 96, 96, 96, 97, 97, 97, 97, 97, 97, 97, 98, 98, 98, 98, 98, 98, 98, 99, 99, 99, 99, 99, 99, 99, 100, 100, 100, 100, 100, 100, 100, 101, 101, 101, 101, 101, 101, 101, 102, 102, 102, 102, 102, 102, 102, 103, 103, 103, 103, 103, 103, 103, 104, 104, 104, 104, 104, 104, 104, 105, 105, 105, 105, 105, 105, 105, 106, 106, 106, 106, 106, 106, 106]\n",
            "['000_back_ear.jpg', '000_right_ear.jpg', '000_down_ear.jpg', '000_zoom_ear.jpg', '000_front_ear.jpg', '000_left_ear.jpg', '000_up_ear.jpg', '001_left_ear.jpg', '001_front_ear.jpg', '001_back_ear.jpg', '001_up_ear.jpg', '001_right_ear.jpg', '001_down_ear.jpg', '001_zoom_ear.jpg', '002_down_ear.jpg', '002_zoom_ear.jpg', '002_left_ear.jpg', '002_right_ear.jpg', '002_back_ear.jpg', '002_up_ear.jpg', '002_front_ear.jpg', '003_right_ear.jpg', '003_left_ear.jpg', '003_back_ear.jpg', '003_zoom_ear.jpg', '003_down_ear.jpg', '003_up_ear.jpg', '003_front_ear.jpg', '004_zoom_ear.jpg', '004_up_ear.jpg', '004_left_ear.jpg', '004_front_ear.jpg', '004_back_ear.jpg', '004_right_ear.jpg', '004_down_ear.jpg', '005_back_ear.jpg', '005_zoom_ear.jpg', '005_down_ear.jpg', '005_right_ear.jpg', '005_front_ear.jpg', '005_up_ear.jpg', '005_left_ear.jpg', '007_zoom_ear.jpg', '007_left_ear.jpg', '007_up_ear.jpg', '007_right_ear.jpg', '007_down_ear.jpg', '007_back_ear.jpg', '007_front_ear.jpg', '008_right_ear.jpg', '008_front_ear.jpg', '008_down_ear.jpg', '008_up_ear.jpg', '008_zoom_ear.jpg', '008_back_ear.jpg', '008_left_ear.jpg', '009_down_ear.jpg', '009_front_ear.jpg', '009_left_ear.jpg', '009_back_ear.jpg', '009_right_ear.jpg', '009_up_ear.jpg', '009_zoom_ear.jpg', '010_left_ear.jpg', '010_down_ear.jpg', '010_right_ear.jpg', '010_zoom_ear.jpg', '010_front_ear.jpg', '010_back_ear.jpg', '010_up_ear.jpg', '011_right_ear.jpg', '011_down_ear.jpg', '011_back_ear.jpg', '011_up_ear.jpg', '011_front_ear.jpg', '011_left_ear.jpg', '011_zoom_ear.jpg', '012_front_ear.jpg', '012_left_ear.jpg', '012_zoom_ear.jpg', '012_back_ear.jpg', '012_right_ear.jpg', '012_up_ear.jpg', '012_down_ear.jpg', '013_back_ear.jpg', '013_front_ear.jpg', '013_up_ear.jpg', '013_zoom_ear.jpg', '013_left_ear.jpg', '013_right_ear.jpg', '013_down_ear.jpg', '014_up_ear.jpg', '014_zoom_ear.jpg', '014_front_ear.jpg', '014_down_ear.jpg', '014_right_ear.jpg', '014_left_ear.jpg', '014_back_ear.jpg', '018_down_ear.jpg', '018_zoom_ear.jpg', '018_left_ear.jpg', '018_back_ear.jpg', '018_right_ear.jpg', '018_front_ear.jpg', '018_up_ear.jpg', '019_back_ear.jpg', '019_up_ear.jpg', '019_left_ear.jpg', '019_down_ear.jpg', '019_front_ear.jpg', '019_right_ear.jpg', '019_zoom_ear.jpg', '020_up_ear.jpg', '020_left_ear.jpg', '020_front_ear.jpg', '020_zoom_ear.jpg', '020_down_ear.jpg', '020_back_ear.jpg', '020_right_ear.jpg', '021_right_ear.jpg', '021_zoom_ear.jpg', '021_back_ear.jpg', '021_up_ear.jpg', '021_left_ear.jpg', '021_front_ear.jpg', '021_down_ear.jpg', '022_zoom_ear.jpg', '022_right_ear.jpg', '022_back_ear.jpg', '022_down_ear.jpg', '022_front_ear.jpg', '022_up_ear.jpg', '022_left_ear.jpg', '023_zoom_ear.jpg', '023_back_ear.jpg', '023_right_ear.jpg', '023_left_ear.jpg', '023_up_ear.jpg', '023_down_ear.jpg', '023_front_ear.jpg', '024_down_ear.jpg', '024_left_ear.jpg', '024_up_ear.jpg', '024_front_ear.jpg', '024_right_ear.jpg', '024_back_ear.jpg', '024_zoom_ear.jpg', '025_up_ear.jpg', '025_right_ear.jpg', '025_down_ear.jpg', '025_left_ear.jpg', '025_back_ear.jpg', '025_zoom_ear.jpg', '025_front_ear.jpg', '026_zoom_ear.jpg', '026_back_ear.jpg', '026_right_ear.jpg', '026_left_ear.jpg', '026_front_ear.jpg', '026_down_ear.jpg', '026_up_ear.jpg', '027_back_ear.jpg', '027_front_ear.jpg', '027_zoom_ear.jpg', '027_up_ear.jpg', '027_down_ear.jpg', '027_left_ear.jpg', '027_right_ear.jpg', '028_down_ear.jpg', '028_back_ear.jpg', '028_up_ear.jpg', '028_left_ear.jpg', '028_right_ear.jpg', '028_zoom_ear.jpg', '028_front_ear.jpg', '029_right_ear.jpg', '029_down_ear.jpg', '029_front_ear.jpg', '029_left_ear.jpg', '029_back_ear.jpg', '029_up_ear.jpg', '029_zoom_ear.jpg', '030_zoom_ear.jpg', '030_right_ear.jpg', '030_down_ear.jpg', '030_front_ear.jpg', '030_back_ear.jpg', '030_left_ear.jpg', '030_up_ear.jpg', '031_right_ear.jpg', '031_zoom_ear.jpg', '031_back_ear.jpg', '031_front_ear.jpg', '031_up_ear.jpg', '031_left_ear.jpg', '031_down_ear.jpg', '032_zoom_ear.jpg', '032_right_ear.jpg', '032_back_ear.jpg', '032_down_ear.jpg', '032_up_ear.jpg', '032_left_ear.jpg', '032_front_ear.jpg', '033_left_ear.jpg', '033_up_ear.jpg', '033_zoom_ear.jpg', '033_right_ear.jpg', '033_front_ear.jpg', '033_back_ear.jpg', '033_down_ear.jpg', '034_left_ear.jpg', '034_back_ear.jpg', '034_up_ear.jpg', '034_zoom_ear.jpg', '034_front_ear.jpg', '034_down_ear.jpg', '034_right_ear.jpg', '035_zoom_ear.jpg', '035_right_ear.jpg', '035_back_ear.jpg', '035_up_ear.jpg', '035_front_ear.jpg', '035_left_ear.jpg', '035_down_ear.jpg', '036_down_ear.jpg', '036_up_ear.jpg', '036_left_ear.jpg', '036_front_ear.jpg', '036_right_ear.jpg', '036_zoom_ear.jpg', '036_back_ear.jpg', '037_zoom_ear.jpg', '037_back_ear.jpg', '037_up_ear.jpg', '037_front_ear.jpg', '037_right_ear.jpg', '037_down_ear.jpg', '037_left_ear.jpg', '038_left_ear.jpg', '038_zoom_ear.jpg', '038_down_ear.jpg', '038_back_ear.jpg', '038_up_ear.jpg', '038_right_ear.jpg', '038_front_ear.jpg', '039_up_ear.jpg', '039_front_ear.jpg', '039_left_ear.jpg', '039_down_ear.jpg', '039_right_ear.jpg', '039_back_ear.jpg', '039_zoom_ear.jpg', '040_right_ear.jpg', '040_left_ear.jpg', '040_zoom_ear.jpg', '040_back_ear.jpg', '040_down_ear.jpg', '040_up_ear.jpg', '040_front_ear.jpg', '041_right_ear.jpg', '041_left_ear.jpg', '041_front_ear.jpg', '041_up_ear.jpg', '041_down_ear.jpg', '041_zoom_ear.jpg', '041_back_ear.jpg', '042_zoom_ear.jpg', '042_up_ear.jpg', '042_back_ear.jpg', '042_right_ear.jpg', '042_front_ear.jpg', '042_down_ear.jpg', '042_left_ear.jpg', '043_zoom_ear.jpg', '043_right_ear.jpg', '043_left_ear.jpg', '043_up_ear.jpg', '043_front_ear.jpg', '043_down_ear.jpg', '043_back_ear.jpg', '044_down_ear.jpg', '044_right_ear.jpg', '044_left_ear.jpg', '044_zoom_ear.jpg', '044_front_ear.jpg', '044_up_ear.jpg', '044_back_ear.jpg', '045_up_ear.jpg', '045_right_ear.jpg', '045_back_ear.jpg', '045_down_ear.jpg', '045_front_ear.jpg', '045_zoom_ear.jpg', '045_left_ear.jpg', '046_right_ear.jpg', '046_zoom_ear.jpg', '046_up_ear.jpg', '046_down_ear.jpg', '046_front_ear.jpg', '046_back_ear.jpg', '046_left_ear.jpg', '047_up_ear.jpg', '047_back_ear.jpg', '047_zoom_ear.jpg', '047_front_ear.jpg', '047_down_ear.jpg', '047_left_ear.jpg', '047_right_ear.jpg', '048_back_ear.jpg', '048_right_ear.jpg', '048_down_ear.jpg', '048_zoom_ear.jpg', '048_left_ear.jpg', '048_front_ear.jpg', '048_up_ear.jpg', '051_back_ear.jpg', '051_front_ear.jpg', '051_up_ear.jpg', '051_zoom_ear.jpg', '051_right_ear.jpg', '051_left_ear.jpg', '051_down_ear.jpg', '052_up_ear.jpg', '052_front_ear.jpg', '052_zoom_ear.jpg', '052_left_ear.jpg', '052_down_ear.jpg', '052_back_ear.jpg', '052_right_ear.jpg', '053_down_ear.jpg', '053_back_ear.jpg', '053_right_ear.jpg', '053_up_ear.jpg', '053_zoom_ear.jpg', '053_front_ear.jpg', '053_left_ear.jpg', '054_zoom_ear.jpg', '054_down_ear.jpg', '054_up_ear.jpg', '054_left_ear.jpg', '054_front_ear.jpg', '054_right_ear.jpg', '054_back_ear.jpg', '055_back_ear.jpg', '055_front_ear.jpg', '055_right_ear.jpg', '055_down_ear.jpg', '055_left_ear.jpg', '055_zoom_ear.jpg', '055_up_ear.jpg', '056_up_ear.jpg', '056_back_ear.jpg', '056_right_ear.jpg', '056_front_ear.jpg', '056_zoom_ear.jpg', '056_down_ear.jpg', '056_left_ear.jpg', '057_up_ear.jpg', '057_right_ear.jpg', '057_back_ear.jpg', '057_down_ear.jpg', '057_front_ear.jpg', '057_zoom_ear.jpg', '057_left_ear.jpg', '058_back_ear.jpg', '058_front_ear.jpg', '058_up_ear.jpg', '058_down_ear.jpg', '058_right_ear.jpg', '058_left_ear.jpg', '058_zoom_ear.jpg', '059_right_ear.jpg', '059_up_ear.jpg', '059_front_ear.jpg', '059_back_ear.jpg', '059_left_ear.jpg', '059_down_ear.jpg', '059_zoom_ear.jpg', '061_back_ear.jpg', '061_front_ear.jpg', '061_down_ear.jpg', '061_right_ear.jpg', '061_left_ear.jpg', '061_up_ear.jpg', '061_zoom_ear.jpg', '062_right_ear.jpg', '062_down_ear.jpg', '062_up_ear.jpg', '062_front_ear.jpg', '062_back_ear.jpg', '062_zoom_ear.jpg', '062_left_ear.jpg', '063_up_ear.jpg', '063_front_ear.jpg', '063_back_ear.jpg', '063_down_ear.jpg', '063_right_ear.jpg', '063_zoom_ear.jpg', '063_left_ear.jpg', '064_down_ear.jpg', '064_back_ear.jpg', '064_right_ear.jpg', '064_up_ear.jpg', '064_zoom_ear.jpg', '064_front_ear.jpg', '064_left_ear.jpg', '065_down_ear.jpg', '065_back_ear.jpg', '065_zoom_ear.jpg', '065_left_ear.jpg', '065_front_ear.jpg', '065_right_ear.jpg', '065_up_ear.jpg', '066_down_ear.jpg', '066_up_ear.jpg', '066_front_ear.jpg', '066_back_ear.jpg', '066_zoom_ear.jpg', '066_right_ear.jpg', '066_left_ear.jpg', '067_down_ear.jpg', '067_left_ear.jpg', '067_right_ear.jpg', '067_up_ear.jpg', '067_zoom_ear.jpg', '067_back_ear.jpg', '067_front_ear.jpg', '068_down_ear.jpg', '068_front_ear.jpg', '068_left_ear.jpg', '068_zoom_ear.jpg', '068_right_ear.jpg', '068_back_ear.jpg', '068_up_ear.jpg', '069_right_ear.jpg', '069_up_ear.jpg', '069_left_ear.jpg', '069_back_ear.jpg', '069_front_ear.jpg', '069_down_ear.jpg', '069_zoom_ear.jpg', '070_up_ear.jpg', '070_back_ear.jpg', '070_zoom_ear.jpg', '070_right_ear.jpg', '070_left_ear.jpg', '070_front_ear.jpg', '070_down_ear.jpg', '071_down_ear.jpg', '071_front_ear.jpg', '071_left_ear.jpg', '071_right_ear.jpg', '071_up_ear.jpg', '071_back_ear.jpg', '071_zoom_ear.jpg', '072_down_ear.jpg', '072_up_ear.jpg', '072_left_ear.jpg', '072_back_ear.jpg', '072_zoom_ear.jpg', '072_front_ear.jpg', '072_right_ear.jpg', '073_up_ear.jpg', '073_front_ear.jpg', '073_right_ear.jpg', '073_down_ear.jpg', '073_back_ear.jpg', '073_left_ear.jpg', '073_zoom_ear.jpg', '074_left_ear.jpg', '074_front_ear.jpg', '074_up_ear.jpg', '074_right_ear.jpg', '074_back_ear.jpg', '074_down_ear.jpg', '074_zoom_ear.jpg', '075_left_ear.jpg', '075_back_ear.jpg', '075_down_ear.jpg', '075_right_ear.jpg', '075_up_ear.jpg', '075_front_ear.jpg', '075_zoom_ear.jpg', '076_front_ear.jpg', '076_zoom_ear.jpg', '076_back_ear.jpg', '076_left_ear.jpg', '076_down_ear.jpg', '076_right_ear.jpg', '076_up_ear.jpg', '077_front_ear.jpg', '077_down_ear.jpg', '077_up_ear.jpg', '077_left_ear.jpg', '077_back_ear.jpg', '077_zoom_ear.jpg', '077_right_ear.jpg', '078_left_ear.jpg', '078_front_ear.jpg', '078_up_ear.jpg', '078_down_ear.jpg', '078_zoom_ear.jpg', '078_right_ear.jpg', '078_back_ear.jpg', '079_down_ear.jpg', '079_front_ear.jpg', '079_right_ear.jpg', '079_up_ear.jpg', '079_left_ear.jpg', '079_back_ear.jpg', '079_zoom_ear.jpg', '080_down_ear.jpg', '080_right_ear.jpg', '080_front_ear.jpg', '080_left_ear.jpg', '080_back_ear.jpg', '080_up_ear.jpg', '080_zoom_ear.jpg', '081_front_ear.jpg', '081_left_ear.jpg', '081_down_ear.jpg', '081_back_ear.jpg', '081_up_ear.jpg', '081_zoom_ear.jpg', '081_right_ear.jpg', '082_left_ear.jpg', '082_down_ear.jpg', '082_back_ear.jpg', '082_front_ear.jpg', '082_right_ear.jpg', '082_zoom_ear.jpg', '082_up_ear.jpg', '083_back_ear.jpg', '083_front_ear.jpg', '083_zoom_ear.jpg', '083_up_ear.jpg', '083_left_ear.jpg', '083_right_ear.jpg', '083_down_ear.jpg', '084_back_ear.jpg', '084_front_ear.jpg', '084_up_ear.jpg', '084_right_ear.jpg', '084_left_ear.jpg', '084_down_ear.jpg', '084_zoom_ear.jpg', '085_zoom_ear.jpg', '085_left_ear.jpg', '085_right_ear.jpg', '085_down_ear.jpg', '085_back_ear.jpg', '085_front_ear.jpg', '085_up_ear.jpg', '086_back_ear.jpg', '086_right_ear.jpg', '086_down_ear.jpg', '086_zoom_ear.jpg', '086_left_ear.jpg', '086_front_ear.jpg', '086_up_ear.jpg', '087_down_ear.jpg', '087_left_ear.jpg', '087_back_ear.jpg', '087_right_ear.jpg', '087_up_ear.jpg', '087_front_ear.jpg', '087_zoom_ear.jpg', '088_right_ear.jpg', '088_zoom_ear.jpg', '088_down_ear.jpg', '088_back_ear.jpg', '088_front_ear.jpg', '088_up_ear.jpg', '088_left_ear.jpg', '089_right_ear.jpg', '089_front_ear.jpg', '089_back_ear.jpg', '089_down_ear.jpg', '089_zoom_ear.jpg', '089_up_ear.jpg', '089_left_ear.jpg', '090_front_ear.jpg', '090_zoom_ear.jpg', '090_up_ear.jpg', '090_left_ear.jpg', '090_down_ear.jpg', '090_right_ear.jpg', '090_back_ear.jpg', '091_down_ear.jpg', '091_back_ear.jpg', '091_up_ear.jpg', '091_zoom_ear.jpg', '091_right_ear.jpg', '091_front_ear.jpg', '091_left_ear.jpg', '092_front_ear.jpg', '092_down_ear.jpg', '092_back_ear.jpg', '092_right_ear.jpg', '092_left_ear.jpg', '092_zoom_ear.jpg', '092_up_ear.jpg', '093_up_ear.jpg', '093_right_ear.jpg', '093_zoom_ear.jpg', '093_back_ear.jpg', '093_front_ear.jpg', '093_down_ear.jpg', '093_left_ear.jpg', '094_left_ear.jpg', '094_right_ear.jpg', '094_back_ear.jpg', '094_zoom_ear.jpg', '094_down_ear.jpg', '094_up_ear.jpg', '094_front_ear.jpg', '095_back_ear.jpg', '095_left_ear.jpg', '095_down_ear.jpg', '095_zoom_ear.jpg', '095_front_ear.jpg', '095_right_ear.jpg', '095_up_ear.jpg', '096_down_ear.jpg', '096_back_ear.jpg', '096_front_ear.jpg', '096_right_ear.jpg', '096_zoom_ear.jpg', '096_up_ear.jpg', '096_left_ear.jpg', '097_zoom_ear.jpg', '097_right_ear.jpg', '097_down_ear.jpg', '097_up_ear.jpg', '097_left_ear.jpg', '097_front_ear.jpg', '097_back_ear.jpg', '098_down_ear.jpg', '098_right_ear.jpg', '098_left_ear.jpg', '098_back_ear.jpg', '098_front_ear.jpg', '098_up_ear.jpg', '098_zoom_ear.jpg', '099_zoom_ear.jpg', '099_front_ear.jpg', '099_down_ear.jpg', '099_right_ear.jpg', '099_left_ear.jpg', '099_up_ear.jpg', '099_back_ear.jpg', '100_down_ear.jpg', '100_back_ear.jpg', '100_left_ear.jpg', '100_zoom_ear.jpg', '100_up_ear.jpg', '100_right_ear.jpg', '100_front_ear.jpg', '101_front_ear.jpg', '101_zoom_ear.jpg', '101_down_ear.jpg', '101_right_ear.jpg', '101_back_ear.jpg', '101_up_ear.jpg', '101_left_ear.jpg', '102_back_ear.jpg', '102_zoom_ear.jpg', '102_down_ear.jpg', '102_left_ear.jpg', '102_right_ear.jpg', '102_front_ear.jpg', '102_up_ear.jpg', '103_up_ear.jpg', '103_left_ear.jpg', '103_back_ear.jpg', '103_zoom_ear.jpg', '103_front_ear.jpg', '103_down_ear.jpg', '103_right_ear.jpg', '104_down_ear.jpg', '104_front_ear.jpg', '104_zoom_ear.jpg', '104_back_ear.jpg', '104_right_ear.jpg', '104_left_ear.jpg', '104_up_ear.jpg', '105_front_ear.jpg', '105_down_ear.jpg', '105_left_ear.jpg', '105_right_ear.jpg', '105_up_ear.jpg', '105_zoom_ear.jpg', '105_back_ear.jpg', '106_right_ear.jpg', '106_left_ear.jpg', '106_down_ear.jpg', '106_up_ear.jpg', '106_back_ear.jpg', '106_zoom_ear.jpg', '106_front_ear.jpg']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-09f49b68a811>:59: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
            "  ear_img = ear_img.resize(target_size, Image.ANTIALIAS)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(700, 3, 50, 180)\n",
            "(700,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(ear_images, sub_labels, test_size=0.382093316519, random_state=42, stratify=sub_labels)\n",
        "# X_train, X_test, y_train, y_test = train_test_split(ear_images, sub_labels, test_size=0.2786885245901639, random_state=42, stratify=sub_labels)\n",
        "# X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.386363636363, random_state=42, stratify=y_train)\n",
        "\n",
        "print('Training dataset:\\n',X_train.shape)\n",
        "print(y_train.shape)\n",
        "# print('Validation dataset:\\n',X_valid.shape)\n",
        "# print(y_valid.shape)\n",
        "print('Test dataset:\\n',X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxumLS3QOES3",
        "outputId": "5f6bf83b-bfa0-4a55-c1f8-75e56bf0ca59"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training dataset:\n",
            " (432, 3, 50, 180)\n",
            "(432,)\n",
            "Test dataset:\n",
            " (268, 3, 50, 180)\n",
            "(268,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conventional convolution"
      ],
      "metadata": {
        "id": "-Iqa_Mc5xUiG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torch.nn\n",
        "import torch.nn.functional\n",
        "import torch.optim\n",
        "from torchvision import models #just for debugging"
      ],
      "metadata": {
        "id": "VbDuNIPfRIH6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Pytorch_BUS_Final_Model_C1(torch.nn.Module):\n",
        "  #  Determine what layers and their order in CNN object\n",
        "  def __init__(self, num_classes=221, num_filters=8, input_shape=(180,50,3)):\n",
        "    super(Pytorch_BUS_Final_Model_C1,self).__init__()\n",
        "    #self.encoder_input = input_shape[-1]\n",
        "    kernel_size = 3\n",
        "    # Encoder Layer1\n",
        "    self.encoder_layer1_name = 'encoder_layer1'\n",
        "    self.encoder_layer1_conv = torch.nn.Conv2d(3,\n",
        "                                               num_filters,\n",
        "                                               kernel_size,\n",
        "                                               padding='same')\n",
        "\n",
        "    self.encoder_layer1_activation = torch.nn.ReLU()\n",
        "    self.encoder_layer1_pooling = torch.nn.MaxPool2d(kernel_size=(2, 2))\n",
        "\n",
        "    # Encoder Layer2\n",
        "    self.encoder_layer2_name = 'encoder_layer2'\n",
        "    self.encoder_layer2_conv = torch.nn.Conv2d(num_filters,\n",
        "                                               2*num_filters,\n",
        "                                               kernel_size,\n",
        "                                               padding='same')\n",
        "    self.encoder_layer2_activation = torch.nn.ReLU()\n",
        "    self.encoder_layer2_batch_norm = torch.nn.BatchNorm2d(2*num_filters,\n",
        "                                                          eps = 1e-3,\n",
        "                                                          momentum = 0.99)\n",
        "    self.encoder_layer2_pooling = torch.nn.MaxPool2d(kernel_size=(2, 2))\n",
        "\n",
        "    # Encoder Layer3\n",
        "    self.encoder_layer3_name = 'encoder_layer3'\n",
        "    self.encoder_layer3_conv = torch.nn.Conv2d(2*num_filters,\n",
        "                                               4*num_filters,\n",
        "                                               kernel_size,\n",
        "                                               padding='same')\n",
        "    self.encoder_layer3_activation = torch.nn.ReLU()\n",
        "    self.encoder_layer3_pooling = torch.nn.MaxPool2d(kernel_size=(2, 2))\n",
        "\n",
        "    # Encoder Layer4\n",
        "    self.encoder_layer4_name = 'encoder_layer4'\n",
        "    self.encoder_layer4_conv = torch.nn.Conv2d(4*num_filters,\n",
        "                                               8*num_filters,\n",
        "                                               kernel_size,\n",
        "                                               padding='same')\n",
        "    self.encoder_layer4_activation = torch.nn.ReLU()\n",
        "    self.encoder_layer4_batch_norm = torch.nn.BatchNorm2d(8*num_filters,\n",
        "                                                          eps = 1e-3,\n",
        "                                                          momentum = 0.99)\n",
        "    self.encoder_layer4_pooling = torch.nn.MaxPool2d(kernel_size=(2, 2))\n",
        "\n",
        "    # Encoder Layer5\n",
        "    self.encoder_layer5_name = 'encoder_layer5'\n",
        "    self.encoder_layer5_conv = torch.nn.Conv2d(8*num_filters,\n",
        "                                               16*num_filters,\n",
        "                                               kernel_size,\n",
        "                                               padding='same')\n",
        "\n",
        "    self.encoder_layer5_activation = torch.nn.ReLU()\n",
        "    self.encoder_layer5_pooling = torch.nn.MaxPool2d(kernel_size=(2, 2))\n",
        "\n",
        "   # Encoder Layer6\n",
        "    self.encoder_layer6_name = 'encoder_layer2'\n",
        "    self.encoder_layer6_conv = torch.nn.Conv2d(16*num_filters,\n",
        "                                               32*num_filters,\n",
        "                                               kernel_size,\n",
        "                                               padding='same')\n",
        "    self.encoder_layer6_activation = torch.nn.ReLU()\n",
        "    self.encoder_layer6_batch_norm = torch.nn.BatchNorm2d(32*num_filters,\n",
        "                                                          eps = 1e-3,\n",
        "                                                          momentum = 0.99)\n",
        "    # Dense layer\n",
        "    self.fc1_flatten = torch.nn.Flatten()\n",
        "    self.fc1_linear = torch.nn.Linear(32*num_filters*(input_shape[0]//(2**5))*(input_shape[1]//(2**5)), num_classes)\n",
        "    self.fc1_activation = torch.nn.Softmax()\n",
        "\n",
        "  def forward(self,x):\n",
        "    # Encoder Layer1\n",
        "    out = self.encoder_layer1_conv(x)\n",
        "    out = self.encoder_layer1_activation(out)\n",
        "    out = self.encoder_layer1_pooling(out)\n",
        "\n",
        "    # Encoder Layer2\n",
        "    out = self.encoder_layer2_conv(out)\n",
        "    out = self.encoder_layer2_activation(out)\n",
        "    out = self.encoder_layer2_batch_norm(out)\n",
        "    out = self.encoder_layer2_pooling(out)\n",
        "\n",
        "    # Encoder Layer3\n",
        "    out = self.encoder_layer3_conv(out)\n",
        "    out = self.encoder_layer3_activation(out)\n",
        "    out = self.encoder_layer3_pooling(out)\n",
        "\n",
        "    # Encoder Layer4\n",
        "    out = self.encoder_layer4_conv(out)\n",
        "    out = self.encoder_layer4_activation(out)\n",
        "    out = self.encoder_layer4_batch_norm(out)\n",
        "    out = self.encoder_layer4_pooling(out)\n",
        "\n",
        "    # Encoder Layer5\n",
        "    out = self.encoder_layer5_conv(out)\n",
        "    out = self.encoder_layer5_activation(out)\n",
        "    out = self.encoder_layer5_pooling(out)\n",
        "\n",
        "    # Encoder Layer6\n",
        "    out = self.encoder_layer6_conv(out)\n",
        "    out = self.encoder_layer6_activation(out)\n",
        "    out = self.encoder_layer6_batch_norm(out)\n",
        "\n",
        "    # Dense Layer\n",
        "    out = self.fc1_flatten(out)\n",
        "    out = self.fc1_linear(out)\n",
        "    out = self.fc1_activation(out)\n",
        "\n",
        "    return out"
      ],
      "metadata": {
        "id": "uVNt1gPIR8gi"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7Bqh1xEXOSs",
        "outputId": "248312bd-b199-4951-feed-1f4f5ea347e0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchinfo import summary\n",
        "\n",
        "pytorch_model_c1 = Pytorch_BUS_Final_Model_C1()\n",
        "summary(pytorch_model_c1, input_size=(1,3,180,50))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwfC7_pYXRVR",
        "outputId": "47161861-3497-4e7d-97c5-7919576eabd5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-0a7d330d2bff>:111: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = self.fc1_activation(out)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "Pytorch_BUS_Final_Model_C1               [1, 221]                  --\n",
              "├─Conv2d: 1-1                            [1, 8, 180, 50]           224\n",
              "├─ReLU: 1-2                              [1, 8, 180, 50]           --\n",
              "├─MaxPool2d: 1-3                         [1, 8, 90, 25]            --\n",
              "├─Conv2d: 1-4                            [1, 16, 90, 25]           1,168\n",
              "├─ReLU: 1-5                              [1, 16, 90, 25]           --\n",
              "├─BatchNorm2d: 1-6                       [1, 16, 90, 25]           32\n",
              "├─MaxPool2d: 1-7                         [1, 16, 45, 12]           --\n",
              "├─Conv2d: 1-8                            [1, 32, 45, 12]           4,640\n",
              "├─ReLU: 1-9                              [1, 32, 45, 12]           --\n",
              "├─MaxPool2d: 1-10                        [1, 32, 22, 6]            --\n",
              "├─Conv2d: 1-11                           [1, 64, 22, 6]            18,496\n",
              "├─ReLU: 1-12                             [1, 64, 22, 6]            --\n",
              "├─BatchNorm2d: 1-13                      [1, 64, 22, 6]            128\n",
              "├─MaxPool2d: 1-14                        [1, 64, 11, 3]            --\n",
              "├─Conv2d: 1-15                           [1, 128, 11, 3]           73,856\n",
              "├─ReLU: 1-16                             [1, 128, 11, 3]           --\n",
              "├─MaxPool2d: 1-17                        [1, 128, 5, 1]            --\n",
              "├─Conv2d: 1-18                           [1, 256, 5, 1]            295,168\n",
              "├─ReLU: 1-19                             [1, 256, 5, 1]            --\n",
              "├─BatchNorm2d: 1-20                      [1, 256, 5, 1]            512\n",
              "├─Flatten: 1-21                          [1, 1280]                 --\n",
              "├─Linear: 1-22                           [1, 221]                  283,101\n",
              "├─Softmax: 1-23                          [1, 221]                  --\n",
              "==========================================================================================\n",
              "Total params: 677,325\n",
              "Trainable params: 677,325\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 13.79\n",
              "==========================================================================================\n",
              "Input size (MB): 0.11\n",
              "Forward/backward pass size (MB): 1.48\n",
              "Params size (MB): 2.71\n",
              "Estimated Total Size (MB): 4.30\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pytorch_model_c1.eval()\n",
        "# output = pytorch_model_c1(torch.Tensor(X_train[0].reshape(1,180,180,3).transpose(0,3,1,2)))\n",
        "# print(output.detach().numpy())\n",
        "# input_x = torch.tensor(X_train[0].reshape(1,180,50,1).transpose(0,3,1,2), device='cuda')\n",
        "input_x = torch.tensor(X_train[0].reshape(1,3,180,50), device='cuda').float()\n",
        "print(input_x.shape)\n",
        "output = pytorch_model_c1(input_x)\n",
        "print(output.shape)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vkohHsDXE7b",
        "outputId": "ee54772b-90d4-4615-d59c-8fc17b3acdc3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 3, 180, 50])\n",
            "torch.Size([1, 221])\n",
            "tensor([[0.0036, 0.0063, 0.0033, 0.0049, 0.0023, 0.0037, 0.0055, 0.0028, 0.0099,\n",
            "         0.0079, 0.0064, 0.0045, 0.0107, 0.0071, 0.0025, 0.0059, 0.0043, 0.0030,\n",
            "         0.0036, 0.0029, 0.0031, 0.0039, 0.0027, 0.0044, 0.0027, 0.0054, 0.0023,\n",
            "         0.0035, 0.0029, 0.0028, 0.0068, 0.0034, 0.0100, 0.0098, 0.0063, 0.0028,\n",
            "         0.0057, 0.0045, 0.0038, 0.0063, 0.0036, 0.0077, 0.0044, 0.0028, 0.0070,\n",
            "         0.0053, 0.0032, 0.0026, 0.0017, 0.0044, 0.0034, 0.0038, 0.0031, 0.0077,\n",
            "         0.0041, 0.0056, 0.0039, 0.0032, 0.0041, 0.0040, 0.0037, 0.0034, 0.0031,\n",
            "         0.0052, 0.0050, 0.0045, 0.0070, 0.0058, 0.0049, 0.0040, 0.0043, 0.0034,\n",
            "         0.0049, 0.0095, 0.0030, 0.0014, 0.0031, 0.0043, 0.0069, 0.0048, 0.0030,\n",
            "         0.0075, 0.0066, 0.0047, 0.0058, 0.0031, 0.0035, 0.0065, 0.0043, 0.0098,\n",
            "         0.0067, 0.0040, 0.0033, 0.0054, 0.0034, 0.0042, 0.0034, 0.0040, 0.0029,\n",
            "         0.0022, 0.0023, 0.0031, 0.0043, 0.0043, 0.0044, 0.0036, 0.0034, 0.0119,\n",
            "         0.0033, 0.0025, 0.0051, 0.0047, 0.0054, 0.0038, 0.0062, 0.0013, 0.0030,\n",
            "         0.0030, 0.0055, 0.0031, 0.0034, 0.0028, 0.0029, 0.0023, 0.0035, 0.0028,\n",
            "         0.0045, 0.0046, 0.0027, 0.0054, 0.0030, 0.0060, 0.0057, 0.0076, 0.0035,\n",
            "         0.0042, 0.0032, 0.0025, 0.0030, 0.0032, 0.0042, 0.0024, 0.0041, 0.0053,\n",
            "         0.0041, 0.0047, 0.0056, 0.0046, 0.0024, 0.0069, 0.0030, 0.0095, 0.0049,\n",
            "         0.0043, 0.0054, 0.0031, 0.0062, 0.0065, 0.0028, 0.0055, 0.0030, 0.0068,\n",
            "         0.0040, 0.0031, 0.0030, 0.0029, 0.0047, 0.0050, 0.0030, 0.0054, 0.0030,\n",
            "         0.0043, 0.0040, 0.0057, 0.0039, 0.0053, 0.0076, 0.0032, 0.0034, 0.0033,\n",
            "         0.0039, 0.0040, 0.0078, 0.0065, 0.0047, 0.0047, 0.0032, 0.0036, 0.0052,\n",
            "         0.0069, 0.0036, 0.0028, 0.0072, 0.0023, 0.0063, 0.0041, 0.0050, 0.0049,\n",
            "         0.0071, 0.0061, 0.0058, 0.0056, 0.0032, 0.0024, 0.0042, 0.0043, 0.0043,\n",
            "         0.0050, 0.0035, 0.0022, 0.0064, 0.0042, 0.0045, 0.0038, 0.0090, 0.0033,\n",
            "         0.0046, 0.0037, 0.0034, 0.0075, 0.0024]], device='cuda:0',\n",
            "       grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-0a7d330d2bff>:111: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = self.fc1_activation(out)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#data\n",
        "training_loader = DataLoader(TensorDataset(torch.tensor(X_train), torch.tensor(y_train)), batch_size=10, pin_memory='True', pin_memory_device='cuda', shuffle=True)\n",
        "validation_loader = DataLoader(TensorDataset(torch.tensor(X_test), torch.tensor(y_test)), batch_size=1, pin_memory='True', pin_memory_device='cuda')\n",
        "#loss function\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "# loss_fn = torch.nn.BCELoss()\n",
        "# loss_fn = torch.nn.BCEWithLogitsLoss()\n",
        "# Optimizers specified in the torch.optim package\n",
        "optimizer = torch.optim.Adam(pytorch_model_c1.parameters())\n",
        "\n",
        "# # import EarlyStopping\n",
        "# from pytorchtools import EarlyStopping"
      ],
      "metadata": {
        "id": "vGUNjmwkdwTG"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def to_categorical(y, num_classes):\n",
        "    \"\"\" 1-hot encodes a tensor \"\"\"\n",
        "    return np.eye(num_classes, dtype='uint8')[y]\n",
        "\n",
        "pytorch_model_c1 = Pytorch_BUS_Final_Model_C1().to(torch.device('cuda'))\n",
        "\n",
        "# manaul training\n",
        "def train_one_epoch():\n",
        "    # training metrics\n",
        "    train_loss = 0\n",
        "    train_correct = 0\n",
        "\n",
        "    # validation metrics\n",
        "    valid_loss = 0\n",
        "    valid_correct = 0\n",
        "\n",
        "\n",
        "    # Here, we use enumerate(training_loader) instead of\n",
        "    # iter(training_loader) so that we can track the batch\n",
        "    # index and do some intra-epoch reporting\n",
        "    pytorch_model_c1.train(True)\n",
        "    for i, data in enumerate(training_loader,0):\n",
        "        # Every data instance is an input + label pair\n",
        "        train_input, train_label = data\n",
        "        # train_input = train_input.unsqueeze(dim=1).float()\n",
        "        train_label= torch.tensor(to_categorical(y=train_label, num_classes=221)).float()\n",
        "        # train_label = train_label[:,None]\n",
        "        if len(train_label.shape)==1:\n",
        "          train_label = train_label.unsqueeze(dim=0)\n",
        "\n",
        "        train_input = train_input.to(torch.device('cuda'))\n",
        "        train_label = train_label.to(torch.device('cuda'))\n",
        "\n",
        "        # print('train_input:',train_input.shape, 'train_label:',train_label.shape)\n",
        "\n",
        "        # Zero your gradients for every batch!\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Make predictions for this batch\n",
        "        train_output = pytorch_model_c1(train_input)\n",
        "        # print('train_input:',train_input.shape, 'train_label:',train_label.shape, 'train_output:',train_output.shape)\n",
        "        # print('train_label:',train_label)\n",
        "        # print('train_output:',train_output)\n",
        "\n",
        "        # Compute the loss and its gradients\n",
        "        loss = loss_fn(train_output, train_label)\n",
        "        loss.backward()\n",
        "\n",
        "        # Adjust learning weights\n",
        "        optimizer.step()\n",
        "\n",
        "        # Gather data and report\n",
        "        train_loss += loss.item()\n",
        "        for batch_count in range(train_output.shape[0]):\n",
        "          if(torch.argmax(train_output[batch_count,:]) == torch.argmax(train_label[batch_count,:])):\n",
        "            train_correct += 1\n",
        "\n",
        "    # print('training epoch complete')\n",
        "    # Here, we use enumerate(validation_loader) instead of\n",
        "    # iter(validation_loader) so that we can track the batch\n",
        "    # index and do some intra-epoch reporting\n",
        "    pytorch_model_c1.train(False)\n",
        "    for i, data in enumerate(validation_loader,0):\n",
        "        # Every data instance is an input + label pair\n",
        "        valid_input, valid_label = data\n",
        "\n",
        "        # valid_input = valid_input.unsqueeze(dim=1).float()\n",
        "        valid_label= torch.tensor(to_categorical(y=valid_label, num_classes=221)).float()\n",
        "        if len(valid_label.shape)==1:\n",
        "          valid_label = valid_label.unsqueeze(dim=0)\n",
        "\n",
        "        valid_input = valid_input.to(torch.device('cuda'))\n",
        "        valid_label = valid_label.to(torch.device('cuda'))\n",
        "\n",
        "        # Make predictions for this batch\n",
        "        valid_output = pytorch_model_c1(valid_input)\n",
        "\n",
        "        # print('valid_input:',valid_input.shape, 'valid_label:',valid_label.shape, 'valid_output:',valid_output.shape)\n",
        "\n",
        "        # Gather data and report\n",
        "        valid_loss += loss_fn(valid_output, valid_label).item()\n",
        "        for batch_count in range(valid_output.shape[0]):\n",
        "          if(torch.argmax(valid_output[batch_count,:]) == torch.argmax(valid_label[batch_count,:])):\n",
        "            valid_correct += 1\n",
        "\n",
        "    print(f\"Training: \\n Training Accuracy: {100*train_correct/len(training_loader.dataset)}%, Average Training Loss: {train_loss/len(training_loader)}\")\n",
        "\n",
        "    print(f\"Validation: \\n Validation Accuracy: {100*valid_correct/len(validation_loader.dataset)}%, Average Validation Loss: {valid_loss/len(validation_loader)}\")\n",
        "\n",
        "    return train_loss, valid_loss"
      ],
      "metadata": {
        "id": "egUMDCzvdHRC"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing in a separate cell so we can easily add more epochs to the same run\n",
        "epoch_number = 0\n",
        "EPOCHS = 100\n",
        "optimizer = torch.optim.Adam(pytorch_model_c1.parameters(), lr=1e-4)\n",
        "for epoch in range(EPOCHS):\n",
        "    print('EPOCH {}:'.format(epoch_number + 1))\n",
        "    train_loss, valid_loss = train_one_epoch()\n",
        "    epoch_number += 1"
      ],
      "metadata": {
        "id": "MyKfEMIfd1FY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "210d8fc3-03a6-4917-85bc-90188692d347"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH 1:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-0a7d330d2bff>:111: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = self.fc1_activation(out)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training: \n",
            " Training Accuracy: 3.7037037037037037%, Average Training Loss: 5.394810286435214\n",
            "Validation: \n",
            " Validation Accuracy: 1.492537313432836%, Average Validation Loss: 5.382887740633381\n",
            "EPOCH 2:\n",
            "Training: \n",
            " Training Accuracy: 7.87037037037037%, Average Training Loss: 5.360558401454579\n",
            "Validation: \n",
            " Validation Accuracy: 6.343283582089552%, Average Validation Loss: 5.352962670041554\n",
            "EPOCH 3:\n",
            "Training: \n",
            " Training Accuracy: 12.037037037037036%, Average Training Loss: 5.314598126844927\n",
            "Validation: \n",
            " Validation Accuracy: 10.074626865671641%, Average Validation Loss: 5.316357642856996\n",
            "EPOCH 4:\n",
            "Training: \n",
            " Training Accuracy: 19.675925925925927%, Average Training Loss: 5.256673671982505\n",
            "Validation: \n",
            " Validation Accuracy: 13.805970149253731%, Average Validation Loss: 5.289759869006143\n",
            "EPOCH 5:\n",
            "Training: \n",
            " Training Accuracy: 27.77777777777778%, Average Training Loss: 5.194505756551569\n",
            "Validation: \n",
            " Validation Accuracy: 17.91044776119403%, Average Validation Loss: 5.263136920644276\n",
            "EPOCH 6:\n",
            "Training: \n",
            " Training Accuracy: 37.03703703703704%, Average Training Loss: 5.124517581679604\n",
            "Validation: \n",
            " Validation Accuracy: 21.64179104477612%, Average Validation Loss: 5.248471656842018\n",
            "EPOCH 7:\n",
            "Training: \n",
            " Training Accuracy: 47.68518518518518%, Average Training Loss: 5.051067514853044\n",
            "Validation: \n",
            " Validation Accuracy: 32.46268656716418%, Average Validation Loss: 5.196765595407628\n",
            "EPOCH 8:\n",
            "Training: \n",
            " Training Accuracy: 61.342592592592595%, Average Training Loss: 4.948861859061501\n",
            "Validation: \n",
            " Validation Accuracy: 33.582089552238806%, Average Validation Loss: 5.161461621967714\n",
            "EPOCH 9:\n",
            "Training: \n",
            " Training Accuracy: 70.60185185185185%, Average Training Loss: 4.855224468491294\n",
            "Validation: \n",
            " Validation Accuracy: 38.43283582089552%, Average Validation Loss: 5.122855770054148\n",
            "EPOCH 10:\n",
            "Training: \n",
            " Training Accuracy: 77.31481481481481%, Average Training Loss: 4.759035977450284\n",
            "Validation: \n",
            " Validation Accuracy: 47.014925373134325%, Average Validation Loss: 5.075885198009548\n",
            "EPOCH 11:\n",
            "Training: \n",
            " Training Accuracy: 81.94444444444444%, Average Training Loss: 4.685413642363115\n",
            "Validation: \n",
            " Validation Accuracy: 49.62686567164179%, Average Validation Loss: 5.048293152851845\n",
            "EPOCH 12:\n",
            "Training: \n",
            " Training Accuracy: 86.11111111111111%, Average Training Loss: 4.631012558937073\n",
            "Validation: \n",
            " Validation Accuracy: 50.0%, Average Validation Loss: 5.075005428114934\n",
            "EPOCH 13:\n",
            "Training: \n",
            " Training Accuracy: 89.35185185185185%, Average Training Loss: 4.5857931917363945\n",
            "Validation: \n",
            " Validation Accuracy: 49.25373134328358%, Average Validation Loss: 5.03625747694898\n",
            "EPOCH 14:\n",
            "Training: \n",
            " Training Accuracy: 91.89814814814815%, Average Training Loss: 4.546826405958696\n",
            "Validation: \n",
            " Validation Accuracy: 59.32835820895522%, Average Validation Loss: 4.98735699013098\n",
            "EPOCH 15:\n",
            "Training: \n",
            " Training Accuracy: 93.98148148148148%, Average Training Loss: 4.512134963815862\n",
            "Validation: \n",
            " Validation Accuracy: 55.59701492537314%, Average Validation Loss: 4.996053261543388\n",
            "EPOCH 16:\n",
            "Training: \n",
            " Training Accuracy: 95.37037037037037%, Average Training Loss: 4.4929069172252305\n",
            "Validation: \n",
            " Validation Accuracy: 54.850746268656714%, Average Validation Loss: 4.987064977190387\n",
            "EPOCH 17:\n",
            "Training: \n",
            " Training Accuracy: 95.60185185185185%, Average Training Loss: 4.475488207556984\n",
            "Validation: \n",
            " Validation Accuracy: 57.46268656716418%, Average Validation Loss: 5.003215556714072\n",
            "EPOCH 18:\n",
            "Training: \n",
            " Training Accuracy: 96.75925925925925%, Average Training Loss: 4.4625607620586045\n",
            "Validation: \n",
            " Validation Accuracy: 49.62686567164179%, Average Validation Loss: 5.016070752001521\n",
            "EPOCH 19:\n",
            "Training: \n",
            " Training Accuracy: 97.45370370370371%, Average Training Loss: 4.452843774448741\n",
            "Validation: \n",
            " Validation Accuracy: 55.223880597014926%, Average Validation Loss: 4.980258189030548\n",
            "EPOCH 20:\n",
            "Training: \n",
            " Training Accuracy: 97.68518518518519%, Average Training Loss: 4.445459680123762\n",
            "Validation: \n",
            " Validation Accuracy: 60.44776119402985%, Average Validation Loss: 4.956849797448116\n",
            "EPOCH 21:\n",
            "Training: \n",
            " Training Accuracy: 97.91666666666667%, Average Training Loss: 4.439135703173551\n",
            "Validation: \n",
            " Validation Accuracy: 52.61194029850746%, Average Validation Loss: 5.044554582282679\n",
            "EPOCH 22:\n",
            "Training: \n",
            " Training Accuracy: 98.37962962962963%, Average Training Loss: 4.434388214891607\n",
            "Validation: \n",
            " Validation Accuracy: 54.850746268656714%, Average Validation Loss: 4.960870612913103\n",
            "EPOCH 23:\n",
            "Training: \n",
            " Training Accuracy: 98.61111111111111%, Average Training Loss: 4.432801322503523\n",
            "Validation: \n",
            " Validation Accuracy: 56.71641791044776%, Average Validation Loss: 5.003923126121066\n",
            "EPOCH 24:\n",
            "Training: \n",
            " Training Accuracy: 98.61111111111111%, Average Training Loss: 4.435659408569336\n",
            "Validation: \n",
            " Validation Accuracy: 51.11940298507463%, Average Validation Loss: 5.024785506191538\n",
            "EPOCH 25:\n",
            "Training: \n",
            " Training Accuracy: 99.07407407407408%, Average Training Loss: 4.427634553475813\n",
            "Validation: \n",
            " Validation Accuracy: 57.08955223880597%, Average Validation Loss: 4.976445121551627\n",
            "EPOCH 26:\n",
            "Training: \n",
            " Training Accuracy: 99.07407407407408%, Average Training Loss: 4.422518795186823\n",
            "Validation: \n",
            " Validation Accuracy: 46.64179104477612%, Average Validation Loss: 5.042403877671085\n",
            "EPOCH 27:\n",
            "Training: \n",
            " Training Accuracy: 99.07407407407408%, Average Training Loss: 4.423013958063993\n",
            "Validation: \n",
            " Validation Accuracy: 58.582089552238806%, Average Validation Loss: 4.972235430532427\n",
            "EPOCH 28:\n",
            "Training: \n",
            " Training Accuracy: 99.07407407407408%, Average Training Loss: 4.423126036470586\n",
            "Validation: \n",
            " Validation Accuracy: 61.940298507462686%, Average Validation Loss: 4.935871337776754\n",
            "EPOCH 29:\n",
            "Training: \n",
            " Training Accuracy: 99.30555555555556%, Average Training Loss: 4.4203796278346665\n",
            "Validation: \n",
            " Validation Accuracy: 60.82089552238806%, Average Validation Loss: 4.923652937163168\n",
            "EPOCH 30:\n",
            "Training: \n",
            " Training Accuracy: 99.53703703703704%, Average Training Loss: 4.419062159278176\n",
            "Validation: \n",
            " Validation Accuracy: 48.134328358208954%, Average Validation Loss: 5.041089684215944\n",
            "EPOCH 31:\n",
            "Training: \n",
            " Training Accuracy: 99.76851851851852%, Average Training Loss: 4.418243885040283\n",
            "Validation: \n",
            " Validation Accuracy: 53.73134328358209%, Average Validation Loss: 4.98205995381768\n",
            "EPOCH 32:\n",
            "Training: \n",
            " Training Accuracy: 99.76851851851852%, Average Training Loss: 4.415143999186429\n",
            "Validation: \n",
            " Validation Accuracy: 59.701492537313435%, Average Validation Loss: 4.97217497718868\n",
            "EPOCH 33:\n",
            "Training: \n",
            " Training Accuracy: 99.76851851851852%, Average Training Loss: 4.415222655643117\n",
            "Validation: \n",
            " Validation Accuracy: 59.32835820895522%, Average Validation Loss: 4.930870758953379\n",
            "EPOCH 34:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.41125936941667\n",
            "Validation: \n",
            " Validation Accuracy: 61.56716417910448%, Average Validation Loss: 4.9076388736269365\n",
            "EPOCH 35:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.409356637434526\n",
            "Validation: \n",
            " Validation Accuracy: 55.59701492537314%, Average Validation Loss: 4.968774955664108\n",
            "EPOCH 36:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.40913445299322\n",
            "Validation: \n",
            " Validation Accuracy: 60.44776119402985%, Average Validation Loss: 4.936669591647475\n",
            "EPOCH 37:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.408378687771884\n",
            "Validation: \n",
            " Validation Accuracy: 63.80597014925373%, Average Validation Loss: 4.930128988934986\n",
            "EPOCH 38:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.408435171300715\n",
            "Validation: \n",
            " Validation Accuracy: 45.149253731343286%, Average Validation Loss: 5.0331153513780285\n",
            "EPOCH 39:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.408041823994029\n",
            "Validation: \n",
            " Validation Accuracy: 60.82089552238806%, Average Validation Loss: 4.912294042644216\n",
            "EPOCH 40:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.407956957817078\n",
            "Validation: \n",
            " Validation Accuracy: 58.208955223880594%, Average Validation Loss: 4.9265549218476705\n",
            "EPOCH 41:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.407877380197698\n",
            "Validation: \n",
            " Validation Accuracy: 60.82089552238806%, Average Validation Loss: 4.9170623359395496\n",
            "EPOCH 42:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.407556262883273\n",
            "Validation: \n",
            " Validation Accuracy: 60.82089552238806%, Average Validation Loss: 4.91582086904725\n",
            "EPOCH 43:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.4075821746479384\n",
            "Validation: \n",
            " Validation Accuracy: 62.3134328358209%, Average Validation Loss: 4.9099734861459305\n",
            "EPOCH 44:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.407516046003862\n",
            "Validation: \n",
            " Validation Accuracy: 63.43283582089552%, Average Validation Loss: 4.895858965702911\n",
            "EPOCH 45:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.4073050238869405\n",
            "Validation: \n",
            " Validation Accuracy: 61.940298507462686%, Average Validation Loss: 4.892523728199859\n",
            "EPOCH 46:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.407248464497653\n",
            "Validation: \n",
            " Validation Accuracy: 53.73134328358209%, Average Validation Loss: 4.998429470987462\n",
            "EPOCH 47:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.407193617387251\n",
            "Validation: \n",
            " Validation Accuracy: 62.3134328358209%, Average Validation Loss: 4.906380269064832\n",
            "EPOCH 48:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.407303766770796\n",
            "Validation: \n",
            " Validation Accuracy: 60.44776119402985%, Average Validation Loss: 4.917800298377649\n",
            "EPOCH 49:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.407145283438942\n",
            "Validation: \n",
            " Validation Accuracy: 57.83582089552239%, Average Validation Loss: 4.926103485164358\n",
            "EPOCH 50:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.4071290709755635\n",
            "Validation: \n",
            " Validation Accuracy: 62.6865671641791%, Average Validation Loss: 4.888467971958331\n",
            "EPOCH 51:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.406952131878246\n",
            "Validation: \n",
            " Validation Accuracy: 60.44776119402985%, Average Validation Loss: 4.9408428846900145\n",
            "EPOCH 52:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.407117442651228\n",
            "Validation: \n",
            " Validation Accuracy: 61.56716417910448%, Average Validation Loss: 4.924144647014675\n",
            "EPOCH 53:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.4069835489446465\n",
            "Validation: \n",
            " Validation Accuracy: 66.7910447761194%, Average Validation Loss: 4.878134441019884\n",
            "EPOCH 54:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.407095768234947\n",
            "Validation: \n",
            " Validation Accuracy: 53.35820895522388%, Average Validation Loss: 4.953600371061866\n",
            "EPOCH 55:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.4071160771630025\n",
            "Validation: \n",
            " Validation Accuracy: 60.44776119402985%, Average Validation Loss: 4.903170551826705\n",
            "EPOCH 56:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.4068052768707275\n",
            "Validation: \n",
            " Validation Accuracy: 58.95522388059702%, Average Validation Loss: 4.919944636857331\n",
            "EPOCH 57:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.406866582957181\n",
            "Validation: \n",
            " Validation Accuracy: 54.1044776119403%, Average Validation Loss: 4.966193912634209\n",
            "EPOCH 58:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.406861435283314\n",
            "Validation: \n",
            " Validation Accuracy: 55.223880597014926%, Average Validation Loss: 4.96179147442775\n",
            "EPOCH 59:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.406759262084961\n",
            "Validation: \n",
            " Validation Accuracy: 57.46268656716418%, Average Validation Loss: 4.916899716676171\n",
            "EPOCH 60:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.4069283333691684\n",
            "Validation: \n",
            " Validation Accuracy: 58.208955223880594%, Average Validation Loss: 4.970903232916077\n",
            "EPOCH 61:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.406669150699269\n",
            "Validation: \n",
            " Validation Accuracy: 56.71641791044776%, Average Validation Loss: 4.922233078017164\n",
            "EPOCH 62:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.406689405441284\n",
            "Validation: \n",
            " Validation Accuracy: 60.07462686567164%, Average Validation Loss: 4.894139707978092\n",
            "EPOCH 63:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.407048344612122\n",
            "Validation: \n",
            " Validation Accuracy: 63.059701492537314%, Average Validation Loss: 4.907516808652166\n",
            "EPOCH 64:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.406960649923845\n",
            "Validation: \n",
            " Validation Accuracy: 51.11940298507463%, Average Validation Loss: 4.992177223091695\n",
            "EPOCH 65:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.406679435209795\n",
            "Validation: \n",
            " Validation Accuracy: 54.1044776119403%, Average Validation Loss: 4.946888665654766\n",
            "EPOCH 66:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.4066138375889174\n",
            "Validation: \n",
            " Validation Accuracy: 61.56716417910448%, Average Validation Loss: 4.8823141535716275\n",
            "EPOCH 67:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.406535484574058\n",
            "Validation: \n",
            " Validation Accuracy: 60.07462686567164%, Average Validation Loss: 4.894172999396253\n",
            "EPOCH 68:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.407288031144575\n",
            "Validation: \n",
            " Validation Accuracy: 58.582089552238806%, Average Validation Loss: 4.906034423344171\n",
            "EPOCH 69:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.4077101295644585\n",
            "Validation: \n",
            " Validation Accuracy: 56.71641791044776%, Average Validation Loss: 4.92109901869475\n",
            "EPOCH 70:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.406671209768816\n",
            "Validation: \n",
            " Validation Accuracy: 58.208955223880594%, Average Validation Loss: 4.930065000235145\n",
            "EPOCH 71:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.40664716200395\n",
            "Validation: \n",
            " Validation Accuracy: 63.059701492537314%, Average Validation Loss: 4.912608913521268\n",
            "EPOCH 72:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.406490791927684\n",
            "Validation: \n",
            " Validation Accuracy: 60.07462686567164%, Average Validation Loss: 4.89314681736391\n",
            "EPOCH 73:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.406487616625699\n",
            "Validation: \n",
            " Validation Accuracy: 60.07462686567164%, Average Validation Loss: 4.885806144173466\n",
            "EPOCH 74:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.406534845178777\n",
            "Validation: \n",
            " Validation Accuracy: 60.07462686567164%, Average Validation Loss: 4.89952624555844\n",
            "EPOCH 75:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.406446814537048\n",
            "Validation: \n",
            " Validation Accuracy: 58.95522388059702%, Average Validation Loss: 4.919391350959664\n",
            "EPOCH 76:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.406488559462807\n",
            "Validation: \n",
            " Validation Accuracy: 57.46268656716418%, Average Validation Loss: 4.923270544009422\n",
            "EPOCH 77:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.406363270499489\n",
            "Validation: \n",
            " Validation Accuracy: 59.701492537313435%, Average Validation Loss: 4.900972111901241\n",
            "EPOCH 78:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.406298442320391\n",
            "Validation: \n",
            " Validation Accuracy: 61.19402985074627%, Average Validation Loss: 4.88686953195885\n",
            "EPOCH 79:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.406397050077265\n",
            "Validation: \n",
            " Validation Accuracy: 55.59701492537314%, Average Validation Loss: 4.945177950076203\n",
            "EPOCH 80:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.4063414335250854\n",
            "Validation: \n",
            " Validation Accuracy: 56.71641791044776%, Average Validation Loss: 4.923327529608314\n",
            "EPOCH 81:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.406357743523338\n",
            "Validation: \n",
            " Validation Accuracy: 57.08955223880597%, Average Validation Loss: 4.939202920714421\n",
            "EPOCH 82:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.406262224370783\n",
            "Validation: \n",
            " Validation Accuracy: 60.44776119402985%, Average Validation Loss: 4.907306172954502\n",
            "EPOCH 83:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.406277504834262\n",
            "Validation: \n",
            " Validation Accuracy: 60.82089552238806%, Average Validation Loss: 4.922422364576539\n",
            "EPOCH 84:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.406245827674866\n",
            "Validation: \n",
            " Validation Accuracy: 58.95522388059702%, Average Validation Loss: 4.899144715337611\n",
            "EPOCH 85:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.406215266747908\n",
            "Validation: \n",
            " Validation Accuracy: 60.82089552238806%, Average Validation Loss: 4.890166570891195\n",
            "EPOCH 86:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.406198208982294\n",
            "Validation: \n",
            " Validation Accuracy: 63.80597014925373%, Average Validation Loss: 4.8816147775792365\n",
            "EPOCH 87:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.406255559487776\n",
            "Validation: \n",
            " Validation Accuracy: 57.46268656716418%, Average Validation Loss: 4.921315533011707\n",
            "EPOCH 88:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.406233375722712\n",
            "Validation: \n",
            " Validation Accuracy: 61.56716417910448%, Average Validation Loss: 4.901473867359446\n",
            "EPOCH 89:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.40637084570798\n",
            "Validation: \n",
            " Validation Accuracy: 60.07462686567164%, Average Validation Loss: 4.909905625813043\n",
            "EPOCH 90:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.406275131485679\n",
            "Validation: \n",
            " Validation Accuracy: 63.43283582089552%, Average Validation Loss: 4.877013327470467\n",
            "EPOCH 91:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.406188217076388\n",
            "Validation: \n",
            " Validation Accuracy: 60.44776119402985%, Average Validation Loss: 4.881709609458696\n",
            "EPOCH 92:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.406213337724859\n",
            "Validation: \n",
            " Validation Accuracy: 61.940298507462686%, Average Validation Loss: 4.874712479648306\n",
            "EPOCH 93:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.406175049868497\n",
            "Validation: \n",
            " Validation Accuracy: 64.55223880597015%, Average Validation Loss: 4.853890187704741\n",
            "EPOCH 94:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.4061626737768\n",
            "Validation: \n",
            " Validation Accuracy: 62.3134328358209%, Average Validation Loss: 4.899464826085675\n",
            "EPOCH 95:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.406211462887851\n",
            "Validation: \n",
            " Validation Accuracy: 57.46268656716418%, Average Validation Loss: 4.919974220332815\n",
            "EPOCH 96:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.406141736290672\n",
            "Validation: \n",
            " Validation Accuracy: 62.3134328358209%, Average Validation Loss: 4.866718820671537\n",
            "EPOCH 97:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.406278133392334\n",
            "Validation: \n",
            " Validation Accuracy: 60.07462686567164%, Average Validation Loss: 4.903539879998164\n",
            "EPOCH 98:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.406185106797651\n",
            "Validation: \n",
            " Validation Accuracy: 58.208955223880594%, Average Validation Loss: 4.914755863929862\n",
            "EPOCH 99:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.40626136823134\n",
            "Validation: \n",
            " Validation Accuracy: 56.71641791044776%, Average Validation Loss: 4.926185339244444\n",
            "EPOCH 100:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.406156496568159\n",
            "Validation: \n",
            " Validation Accuracy: 55.59701492537314%, Average Validation Loss: 4.911004409861209\n"
          ]
        }
      ]
    }
  ]
}