{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shujaat123/Ear_Biometrics/blob/main/Pytorch_Ear_Biometric_with_deformableConv.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57mAz8uQMn9G",
        "outputId": "cded5a9a-885d-4457-ee29-a7c973e049e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wget in /usr/local/lib/python3.10/dist-packages (3.2)\n",
            "Requirement already satisfied: py7zr in /usr/local/lib/python3.10/dist-packages (0.20.5)\n",
            "Requirement already satisfied: texttable in /usr/local/lib/python3.10/dist-packages (from py7zr) (1.6.7)\n",
            "Requirement already satisfied: pycryptodomex>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from py7zr) (3.18.0)\n",
            "Requirement already satisfied: pyzstd>=0.14.4 in /usr/local/lib/python3.10/dist-packages (from py7zr) (0.15.9)\n",
            "Requirement already satisfied: pyppmd<1.1.0,>=0.18.1 in /usr/local/lib/python3.10/dist-packages (from py7zr) (1.0.0)\n",
            "Requirement already satisfied: pybcj>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from py7zr) (1.0.1)\n",
            "Requirement already satisfied: multivolumefile>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from py7zr) (0.2.3)\n",
            "Requirement already satisfied: brotli>=1.0.9 in /usr/local/lib/python3.10/dist-packages (from py7zr) (1.0.9)\n",
            "Requirement already satisfied: inflate64>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from py7zr) (0.3.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from py7zr) (5.9.5)\n"
          ]
        }
      ],
      "source": [
        "## Load useful packages\n",
        "!pip install wget\n",
        "!pip install py7zr"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import py7zr\n",
        "from zipfile import ZipFile\n",
        "from random import sample\n",
        "import PIL.Image as Image\n",
        "import matplotlib.pyplot as plt\n",
        "from  sklearn.model_selection import train_test_split\n",
        "from os import listdir\n",
        "from os import path\n",
        "import h5py\n",
        "import numpy as np\n",
        "import wget"
      ],
      "metadata": {
        "id": "WaA0QTb9MwPK"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# exect defination used in keras\n",
        "def to_categorical(y, num_classes=None, dtype=\"float32\"):\n",
        "    \"\"\"Converts a class vector (integers) to binary class matrix.\n",
        "    E.g. for use with `categorical_crossentropy`.\n",
        "    Args:\n",
        "        y: Array-like with class values to be converted into a matrix\n",
        "            (integers from 0 to `num_classes - 1`).\n",
        "        num_classes: Total number of classes. If `None`, this would be inferred\n",
        "          as `max(y) + 1`.\n",
        "        dtype: The data type expected by the input. Default: `'float32'`.\n",
        "    Returns:\n",
        "        A binary matrix representation of the input as a NumPy array. The class\n",
        "        axis is placed last.\n",
        "    Example:\n",
        "    >>> a = tf.keras.utils.to_categorical([0, 1, 2, 3], num_classes=4)\n",
        "    >>> print(a)\n",
        "    [[1. 0. 0. 0.]\n",
        "     [0. 1. 0. 0.]\n",
        "     [0. 0. 1. 0.]\n",
        "     [0. 0. 0. 1.]]\n",
        "    >>> b = tf.constant([.9, .04, .03, .03,\n",
        "    ...                  .3, .45, .15, .13,\n",
        "    ...                  .04, .01, .94, .05,\n",
        "    ...                  .12, .21, .5, .17],\n",
        "    ...                 shape=[4, 4])\n",
        "    >>> loss = tf.keras.backend.categorical_crossentropy(a, b)\n",
        "    >>> print(np.around(loss, 5))\n",
        "    [0.10536 0.82807 0.1011  1.77196]\n",
        "    >>> loss = tf.keras.backend.categorical_crossentropy(a, a)\n",
        "    >>> print(np.around(loss, 5))\n",
        "    [0. 0. 0. 0.]\n",
        "    \"\"\"\n",
        "    y = np.array(y, dtype=\"int\")\n",
        "    input_shape = y.shape\n",
        "\n",
        "    # Shrink the last dimension if the shape is (..., 1).\n",
        "    if input_shape and input_shape[-1] == 1 and len(input_shape) > 1:\n",
        "        input_shape = tuple(input_shape[:-1])\n",
        "\n",
        "    y = y.reshape(-1)\n",
        "    if not num_classes:\n",
        "        num_classes = np.max(y) + 1\n",
        "    n = y.shape[0]\n",
        "    categorical = np.zeros((n, num_classes), dtype=dtype)\n",
        "    categorical[np.arange(n), y] = 1\n",
        "    output_shape = input_shape + (num_classes,)\n",
        "    categorical = np.reshape(categorical, output_shape)\n",
        "    return categorical"
      ],
      "metadata": {
        "id": "O9__nX2ZM8dl"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # LOADING IITD Dataset\n",
        "# data_path = 'https://github.com/Shujaat123/Ear_Biometrics/blob/main/datasets/IITD_Dataset.7z?raw=true'\n",
        "# filename = 'IITD_Dataset.7z'\n",
        "# if(path.exists(filename)):\n",
        "#   !rm $filename\n",
        "#   print('existing file:', filename, ' has been deleted')\n",
        "# print('downloading latest version of file:', filename)\n",
        "# wget.download(data_path, filename)\n",
        "# print('DONE')\n",
        "\n",
        "# with py7zr.SevenZipFile('IITD_Dataset.7z', mode='r') as z:\n",
        "#     z.extractall()\n",
        "# !ls\n",
        "\n",
        "# # Processing IITD_dataset\n",
        "# src_dir = 'ear/processed/221'\n",
        "# images_name = listdir(src_dir)\n",
        "# images_name_temp = []\n",
        "# subjects = []\n",
        "# for img_ind in range(0,len(images_name)):\n",
        "#   if(not(images_name[img_ind]=='Thumbs.db')):\n",
        "#     subjects.append(int(images_name[img_ind].split('_')[0]))\n",
        "#     images_name_temp.append(images_name[img_ind])\n",
        "\n",
        "# images_name = images_name_temp\n",
        "# images_name_ord = []\n",
        "# subjects_ord = []\n",
        "\n",
        "# sub_ind = sorted(range(len(subjects)),key=subjects.__getitem__)\n",
        "# for pos, item in enumerate(sub_ind):\n",
        "#   images_name_ord.append(images_name[item])\n",
        "#   subjects_ord.append(subjects[item])\n",
        "\n",
        "# images_name = images_name_ord\n",
        "# subjects = subjects_ord\n",
        "\n",
        "# print(subjects)\n",
        "# print(images_name)\n",
        "\n",
        "# img_ind = 0\n",
        "# ear_images = []\n",
        "# sub_labels = [];\n",
        "# target_size = (180, 50)\n",
        "\n",
        "# for sub_ind in range(0,len(subjects)):\n",
        "#   img_path = src_dir+'/'+images_name[sub_ind]\n",
        "#   ear_img = (plt.imread(img_path))/255\n",
        "\n",
        "#   ear_img = Image.open(img_path)\n",
        "#   ear_img = ear_img.resize(target_size, Image.ANTIALIAS)\n",
        "#   ear_img = np.asarray(ear_img).astype(np.float32)/255\n",
        "\n",
        "#   ear_images.append(ear_img)\n",
        "#   sub_labels.append(subjects[sub_ind]-1)\n",
        "\n",
        "# ear_images = np.array(ear_images)\n",
        "# sub_labels = to_categorical(np.array(sub_labels))\n",
        "\n",
        "# ear_images = np.expand_dims(ear_images, axis=3)\n",
        "# # sub_labels = np.expand_dims(sub_labels, axis=2)\n",
        "\n",
        "# ear_images = np.concatenate((ear_images,ear_images,ear_images), axis=3)\n",
        "\n",
        "# print(ear_images.shape)\n",
        "# print(sub_labels.shape)\n",
        "\n",
        "\n",
        "## Load useful packages\n",
        "!pip install wget\n",
        "!pip install py7zr\n",
        "\n",
        "import keras\n",
        "import py7zr\n",
        "from zipfile import ZipFile\n",
        "from random import sample\n",
        "\n",
        "import PIL.Image as Image\n",
        "from scipy import io\n",
        "import matplotlib.pyplot as plt\n",
        "from  sklearn.model_selection import train_test_split\n",
        "from os import listdir\n",
        "from os import path\n",
        "import h5py\n",
        "import keras.backend as K\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import wget\n",
        "from keras import regularizers\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.layers import *\n",
        "from keras.models import Model\n",
        "from keras.models import load_model\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "\n",
        "data_path = 'https://github.com/Alishba18001778/EarClassification/blob/main/IITD_Data_Tensor.mat?raw=true'\n",
        "Data_filename = 'IITD_Data_Tensor.mat'\n",
        "\n",
        "data_path_labels = 'https://github.com/Alishba18001778/EarClassification/blob/main/IITD_Labels.mat?raw=true'\n",
        "labels_filename = 'IITD_Labels.mat'\n",
        "\n",
        "if(path.exists(labels_filename)):\n",
        "  !rm $labels_filename\n",
        "  print('existing file:', labels_filename, ' has been deleted')\n",
        "print('downloading latest version of file:', labels_filename)\n",
        "wget.download(data_path_labels, labels_filename)\n",
        "\n",
        "if(path.exists(Data_filename)):\n",
        "  !rm $Data_filename\n",
        "  print('existing file:', Data_filename, ' has been deleted')\n",
        "print('downloading latest version of file:', Data_filename)\n",
        "wget.download(data_path, Data_filename)\n",
        "#\n",
        "u = io.loadmat('IITD_Data_Tensor.mat')\n",
        "v = io.loadmat('IITD_Labels.mat')\n",
        "sub_labels = v[\"sub_labels\"]\n",
        "sub_labels = np.squeeze(sub_labels.transpose())\n",
        "ear_images = u[\"ear_images\"]\n",
        "ear_images = np.array(ear_images)\n",
        "\n",
        "# sub_labels = to_categorical(np.array(sub_labels))\n",
        "print(ear_images.shape)\n",
        "print(sub_labels.shape)"
      ],
      "metadata": {
        "id": "gzlbFf3DNrDz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13c872fe-227d-4e09-f521-b6e5e6950f5b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wget in /usr/local/lib/python3.10/dist-packages (3.2)\n",
            "Requirement already satisfied: py7zr in /usr/local/lib/python3.10/dist-packages (0.20.5)\n",
            "Requirement already satisfied: texttable in /usr/local/lib/python3.10/dist-packages (from py7zr) (1.6.7)\n",
            "Requirement already satisfied: pycryptodomex>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from py7zr) (3.18.0)\n",
            "Requirement already satisfied: pyzstd>=0.14.4 in /usr/local/lib/python3.10/dist-packages (from py7zr) (0.15.9)\n",
            "Requirement already satisfied: pyppmd<1.1.0,>=0.18.1 in /usr/local/lib/python3.10/dist-packages (from py7zr) (1.0.0)\n",
            "Requirement already satisfied: pybcj>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from py7zr) (1.0.1)\n",
            "Requirement already satisfied: multivolumefile>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from py7zr) (0.2.3)\n",
            "Requirement already satisfied: brotli>=1.0.9 in /usr/local/lib/python3.10/dist-packages (from py7zr) (1.0.9)\n",
            "Requirement already satisfied: inflate64>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from py7zr) (0.3.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from py7zr) (5.9.5)\n",
            "existing file: IITD_Labels.mat  has been deleted\n",
            "downloading latest version of file: IITD_Labels.mat\n",
            "existing file: IITD_Data_Tensor.mat  has been deleted\n",
            "downloading latest version of file: IITD_Data_Tensor.mat\n",
            "(793, 180, 50)\n",
            "(793,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(ear_images, sub_labels, test_size=0.382093316519, random_state=42, stratify=sub_labels)\n",
        "# X_train, X_test, y_train, y_test = train_test_split(ear_images, sub_labels, test_size=0.2786885245901639, random_state=42, stratify=sub_labels)\n",
        "# X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.386363636363, random_state=42, stratify=y_train)\n",
        "\n",
        "print('Training dataset:\\n',X_train.shape)\n",
        "print(y_train.shape)\n",
        "# print('Validation dataset:\\n',X_valid.shape)\n",
        "# print(y_valid.shape)\n",
        "print('Test dataset:\\n',X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxumLS3QOES3",
        "outputId": "7a08e661-8590-4793-c9b5-50f1bb0795ad"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training dataset:\n",
            " (490, 180, 50)\n",
            "(490,)\n",
            "Test dataset:\n",
            " (303, 180, 50)\n",
            "(303,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deformable Convolution"
      ],
      "metadata": {
        "id": "vvho6_CgxPnO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.ops\n",
        "from torch import nn\n",
        "\n",
        "class DeformableConv2d(nn.Module):\n",
        "    def __init__(self,\n",
        "                 in_channels,\n",
        "                 out_channels,\n",
        "                 kernel_size=3,\n",
        "                 stride=1,\n",
        "                 padding=1,\n",
        "                 bias=False):\n",
        "\n",
        "        super(DeformableConv2d, self).__init__()\n",
        "\n",
        "        assert type(kernel_size) == tuple or type(kernel_size) == int\n",
        "\n",
        "        kernel_size = kernel_size if type(kernel_size) == tuple else (kernel_size, kernel_size)\n",
        "        self.stride = stride if type(stride) == tuple else (stride, stride)\n",
        "        self.padding = padding\n",
        "\n",
        "        self.offset_conv = nn.Conv2d(in_channels,\n",
        "                                     2 * kernel_size[0] * kernel_size[1],\n",
        "                                     kernel_size=kernel_size,\n",
        "                                     stride=stride,\n",
        "                                     padding=self.padding,\n",
        "                                     bias=True)\n",
        "\n",
        "        nn.init.constant_(self.offset_conv.weight, 0.)\n",
        "        nn.init.constant_(self.offset_conv.bias, 0.)\n",
        "\n",
        "        self.modulator_conv = nn.Conv2d(in_channels,\n",
        "                                     1 * kernel_size[0] * kernel_size[1],\n",
        "                                     kernel_size=kernel_size,\n",
        "                                     stride=stride,\n",
        "                                     padding=self.padding,\n",
        "                                     bias=True)\n",
        "\n",
        "        nn.init.constant_(self.modulator_conv.weight, 0.)\n",
        "        nn.init.constant_(self.modulator_conv.bias, 0.)\n",
        "\n",
        "        self.regular_conv = nn.Conv2d(in_channels=in_channels,\n",
        "                                      out_channels=out_channels,\n",
        "                                      kernel_size=kernel_size,\n",
        "                                      stride=stride,\n",
        "                                      padding=self.padding,\n",
        "                                      bias=bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        #h, w = x.shape[2:]\n",
        "        #max_offset = max(h, w)/4.\n",
        "\n",
        "        offset = self.offset_conv(x)#.clamp(-max_offset, max_offset)\n",
        "        modulator = 2. * torch.sigmoid(self.modulator_conv(x))\n",
        "\n",
        "        x = torchvision.ops.deform_conv2d(input=x,\n",
        "                                          offset=offset,\n",
        "                                          weight=self.regular_conv.weight,\n",
        "                                          bias=self.regular_conv.bias,\n",
        "                                          padding=self.padding,\n",
        "                                          mask=modulator,\n",
        "                                          stride=self.stride,\n",
        "                                          )\n",
        "        return x"
      ],
      "metadata": {
        "id": "7lBuHI7zxPNW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conventional convolution"
      ],
      "metadata": {
        "id": "-Iqa_Mc5xUiG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torch.nn\n",
        "import torch.nn.functional\n",
        "import torch.optim\n",
        "from torchvision import models #just for debugging\n",
        "\n"
      ],
      "metadata": {
        "id": "VbDuNIPfRIH6"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Pytorch_BUS_Final_Model_C1(torch.nn.Module):\n",
        "  #  Determine what layers and their order in CNN object\n",
        "  def __init__(self, num_classes=221, num_filters=8, input_shape=(180,50,1)):\n",
        "    super(Pytorch_BUS_Final_Model_C1,self).__init__()\n",
        "    #self.encoder_input = input_shape[-1]\n",
        "    kernel_size = 3\n",
        "    # Encoder Layer1\n",
        "    self.encoder_layer1_name = 'encoder_layer1'\n",
        "    self.encoder_layer1_conv = torch.nn.Conv2d(1,\n",
        "                                               num_filters,\n",
        "                                               kernel_size,\n",
        "                                               padding='same')\n",
        "    # self.encoder_layer1_conv = DeformableConv2d(1, num_filters, kernel_size=kernel_size, stride=1, padding=1, bias=True)\n",
        "\n",
        "    self.encoder_layer1_activation = torch.nn.ReLU()\n",
        "    self.encoder_layer1_pooling = torch.nn.MaxPool2d(kernel_size=(2, 2))\n",
        "\n",
        "    # Encoder Layer2\n",
        "    self.encoder_layer2_name = 'encoder_layer2'\n",
        "    self.encoder_layer2_conv = torch.nn.Conv2d(num_filters,\n",
        "                                               2*num_filters,\n",
        "                                               kernel_size,\n",
        "                                               padding='same')\n",
        "    self.encoder_layer2_activation = torch.nn.ReLU()\n",
        "    self.encoder_layer2_batch_norm = torch.nn.BatchNorm2d(2*num_filters,\n",
        "                                                          eps = 1e-3,\n",
        "                                                          momentum = 0.99)\n",
        "    self.encoder_layer2_pooling = torch.nn.MaxPool2d(kernel_size=(2, 2))\n",
        "\n",
        "    # Encoder Layer3\n",
        "    self.encoder_layer3_name = 'encoder_layer3'\n",
        "    self.encoder_layer3_conv = torch.nn.Conv2d(2*num_filters,\n",
        "                                               4*num_filters,\n",
        "                                               kernel_size,\n",
        "                                               padding='same')\n",
        "    self.encoder_layer3_activation = torch.nn.ReLU()\n",
        "    self.encoder_layer3_pooling = torch.nn.MaxPool2d(kernel_size=(2, 2))\n",
        "\n",
        "    # Encoder Layer4\n",
        "    self.encoder_layer4_name = 'encoder_layer4'\n",
        "    self.encoder_layer4_conv = torch.nn.Conv2d(4*num_filters,\n",
        "                                               8*num_filters,\n",
        "                                               kernel_size,\n",
        "                                               padding='same')\n",
        "    self.encoder_layer4_activation = torch.nn.ReLU()\n",
        "    self.encoder_layer4_batch_norm = torch.nn.BatchNorm2d(8*num_filters,\n",
        "                                                          eps = 1e-3,\n",
        "                                                          momentum = 0.99)\n",
        "    self.encoder_layer4_pooling = torch.nn.MaxPool2d(kernel_size=(2, 2))\n",
        "\n",
        "    # Encoder Layer5\n",
        "    self.encoder_layer5_name = 'encoder_layer5'\n",
        "    # self.encoder_layer5_conv = torch.nn.Conv2d(8*num_filters,\n",
        "    #                                            16*num_filters,\n",
        "    #                                            kernel_size,\n",
        "    #                                            padding='same')\n",
        "    self.encoder_layer5_conv = DeformableConv2d(8*num_filters, 16*num_filters, kernel_size=kernel_size, stride=1, padding=1, bias=True)\n",
        "\n",
        "    self.encoder_layer5_activation = torch.nn.ReLU()\n",
        "    self.encoder_layer5_pooling = torch.nn.MaxPool2d(kernel_size=(2, 2))\n",
        "\n",
        "   # Encoder Layer6\n",
        "    self.encoder_layer6_name = 'encoder_layer2'\n",
        "    self.encoder_layer6_conv = torch.nn.Conv2d(16*num_filters,\n",
        "                                               32*num_filters,\n",
        "                                               kernel_size,\n",
        "                                               padding='same')\n",
        "    self.encoder_layer6_activation = torch.nn.ReLU()\n",
        "    self.encoder_layer6_batch_norm = torch.nn.BatchNorm2d(32*num_filters,\n",
        "                                                          eps = 1e-3,\n",
        "                                                          momentum = 0.99)\n",
        "    # Dense layer\n",
        "    self.fc1_flatten = torch.nn.Flatten()\n",
        "    self.fc1_linear = torch.nn.Linear(32*num_filters*(input_shape[0]//(2**5))*(input_shape[1]//(2**5)), num_classes)\n",
        "    self.fc1_activation = torch.nn.Softmax()\n",
        "\n",
        "  def forward(self,x):\n",
        "    # Encoder Layer1\n",
        "    out = self.encoder_layer1_conv(x)\n",
        "    out = self.encoder_layer1_activation(out)\n",
        "    out = self.encoder_layer1_pooling(out)\n",
        "\n",
        "    # Encoder Layer2\n",
        "    out = self.encoder_layer2_conv(out)\n",
        "    out = self.encoder_layer2_activation(out)\n",
        "    out = self.encoder_layer2_batch_norm(out)\n",
        "    out = self.encoder_layer2_pooling(out)\n",
        "\n",
        "    # Encoder Layer3\n",
        "    out = self.encoder_layer3_conv(out)\n",
        "    out = self.encoder_layer3_activation(out)\n",
        "    out = self.encoder_layer3_pooling(out)\n",
        "\n",
        "    # Encoder Layer4\n",
        "    out = self.encoder_layer4_conv(out)\n",
        "    out = self.encoder_layer4_activation(out)\n",
        "    out = self.encoder_layer4_batch_norm(out)\n",
        "    out = self.encoder_layer4_pooling(out)\n",
        "\n",
        "    # Encoder Layer5\n",
        "    out = self.encoder_layer5_conv(out)\n",
        "    out = self.encoder_layer5_activation(out)\n",
        "    out = self.encoder_layer5_pooling(out)\n",
        "\n",
        "    # Encoder Layer6\n",
        "    out = self.encoder_layer6_conv(out)\n",
        "    out = self.encoder_layer6_activation(out)\n",
        "    out = self.encoder_layer6_batch_norm(out)\n",
        "\n",
        "    # Dense Layer\n",
        "    out = self.fc1_flatten(out)\n",
        "    out = self.fc1_linear(out)\n",
        "    out = self.fc1_activation(out)\n",
        "\n",
        "    return out"
      ],
      "metadata": {
        "id": "uVNt1gPIR8gi"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7Bqh1xEXOSs",
        "outputId": "b9cbc498-e53a-41e7-aad2-cbdc657af037"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.10/dist-packages (1.8.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchinfo import summary\n",
        "#from torchsummary import summary\n",
        "\n",
        "pytorch_model_c1 = Pytorch_BUS_Final_Model_C1()\n",
        "summary(pytorch_model_c1, input_size=(1,1,180,50))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwfC7_pYXRVR",
        "outputId": "bfef6c96-c348-47ed-b79a-395245907bb8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-11e1958f7583>:113: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = self.fc1_activation(out)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "Pytorch_BUS_Final_Model_C1               [1, 221]                  --\n",
              "├─Conv2d: 1-1                            [1, 8, 180, 50]           80\n",
              "├─ReLU: 1-2                              [1, 8, 180, 50]           --\n",
              "├─MaxPool2d: 1-3                         [1, 8, 90, 25]            --\n",
              "├─Conv2d: 1-4                            [1, 16, 90, 25]           1,168\n",
              "├─ReLU: 1-5                              [1, 16, 90, 25]           --\n",
              "├─BatchNorm2d: 1-6                       [1, 16, 90, 25]           32\n",
              "├─MaxPool2d: 1-7                         [1, 16, 45, 12]           --\n",
              "├─Conv2d: 1-8                            [1, 32, 45, 12]           4,640\n",
              "├─ReLU: 1-9                              [1, 32, 45, 12]           --\n",
              "├─MaxPool2d: 1-10                        [1, 32, 22, 6]            --\n",
              "├─Conv2d: 1-11                           [1, 64, 22, 6]            18,496\n",
              "├─ReLU: 1-12                             [1, 64, 22, 6]            --\n",
              "├─BatchNorm2d: 1-13                      [1, 64, 22, 6]            128\n",
              "├─MaxPool2d: 1-14                        [1, 64, 11, 3]            --\n",
              "├─DeformableConv2d: 1-15                 [1, 128, 11, 3]           73,856\n",
              "│    └─Conv2d: 2-1                       [1, 18, 11, 3]            10,386\n",
              "│    └─Conv2d: 2-2                       [1, 9, 11, 3]             5,193\n",
              "├─ReLU: 1-16                             [1, 128, 11, 3]           --\n",
              "├─MaxPool2d: 1-17                        [1, 128, 5, 1]            --\n",
              "├─Conv2d: 1-18                           [1, 256, 5, 1]            295,168\n",
              "├─ReLU: 1-19                             [1, 256, 5, 1]            --\n",
              "├─BatchNorm2d: 1-20                      [1, 256, 5, 1]            512\n",
              "├─Flatten: 1-21                          [1, 1280]                 --\n",
              "├─Linear: 1-22                           [1, 221]                  283,101\n",
              "├─Softmax: 1-23                          [1, 221]                  --\n",
              "==========================================================================================\n",
              "Total params: 692,760\n",
              "Trainable params: 692,760\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 10.57\n",
              "==========================================================================================\n",
              "Input size (MB): 0.04\n",
              "Forward/backward pass size (MB): 1.45\n",
              "Params size (MB): 2.48\n",
              "Estimated Total Size (MB): 3.97\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pytorch_model_c1.eval()\n",
        "# output = pytorch_model_c1(torch.Tensor(X_train[0].reshape(1,180,180,3).transpose(0,3,1,2)))\n",
        "# print(output.detach().numpy())\n",
        "# input_x = torch.tensor(X_train[0].reshape(1,180,50,1).transpose(0,3,1,2), device='cuda')\n",
        "input_x = torch.tensor(X_train[0].reshape(1,1,180,50), device='cuda').float()\n",
        "print(input_x.shape)\n",
        "output = pytorch_model_c1(input_x)\n",
        "print(output.shape)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vkohHsDXE7b",
        "outputId": "9d8c98c2-4a12-40e3-af17-bb89efbdb101"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1, 180, 50])\n",
            "torch.Size([1, 221])\n",
            "tensor([[0.0085, 0.0053, 0.0041, 0.0074, 0.0044, 0.0034, 0.0038, 0.0041, 0.0057,\n",
            "         0.0026, 0.0033, 0.0035, 0.0034, 0.0038, 0.0088, 0.0077, 0.0022, 0.0052,\n",
            "         0.0039, 0.0073, 0.0022, 0.0039, 0.0040, 0.0020, 0.0068, 0.0037, 0.0056,\n",
            "         0.0018, 0.0040, 0.0041, 0.0057, 0.0049, 0.0057, 0.0067, 0.0075, 0.0053,\n",
            "         0.0035, 0.0056, 0.0069, 0.0035, 0.0090, 0.0080, 0.0035, 0.0045, 0.0051,\n",
            "         0.0026, 0.0029, 0.0030, 0.0023, 0.0025, 0.0020, 0.0061, 0.0029, 0.0054,\n",
            "         0.0073, 0.0040, 0.0035, 0.0055, 0.0022, 0.0051, 0.0053, 0.0055, 0.0047,\n",
            "         0.0059, 0.0077, 0.0042, 0.0029, 0.0049, 0.0058, 0.0049, 0.0057, 0.0019,\n",
            "         0.0024, 0.0026, 0.0034, 0.0051, 0.0050, 0.0043, 0.0056, 0.0042, 0.0024,\n",
            "         0.0092, 0.0030, 0.0024, 0.0060, 0.0023, 0.0028, 0.0027, 0.0025, 0.0020,\n",
            "         0.0036, 0.0035, 0.0045, 0.0074, 0.0035, 0.0041, 0.0054, 0.0110, 0.0050,\n",
            "         0.0040, 0.0064, 0.0046, 0.0033, 0.0021, 0.0029, 0.0042, 0.0050, 0.0034,\n",
            "         0.0063, 0.0042, 0.0037, 0.0039, 0.0069, 0.0045, 0.0012, 0.0033, 0.0063,\n",
            "         0.0040, 0.0036, 0.0036, 0.0027, 0.0039, 0.0064, 0.0072, 0.0112, 0.0019,\n",
            "         0.0031, 0.0035, 0.0047, 0.0042, 0.0069, 0.0047, 0.0038, 0.0038, 0.0047,\n",
            "         0.0038, 0.0060, 0.0017, 0.0052, 0.0060, 0.0036, 0.0036, 0.0061, 0.0031,\n",
            "         0.0057, 0.0058, 0.0029, 0.0072, 0.0044, 0.0029, 0.0072, 0.0095, 0.0049,\n",
            "         0.0027, 0.0040, 0.0047, 0.0047, 0.0043, 0.0026, 0.0048, 0.0042, 0.0049,\n",
            "         0.0030, 0.0081, 0.0044, 0.0021, 0.0026, 0.0028, 0.0035, 0.0033, 0.0034,\n",
            "         0.0025, 0.0020, 0.0043, 0.0068, 0.0025, 0.0122, 0.0083, 0.0023, 0.0082,\n",
            "         0.0047, 0.0084, 0.0040, 0.0032, 0.0043, 0.0042, 0.0029, 0.0030, 0.0040,\n",
            "         0.0066, 0.0038, 0.0050, 0.0030, 0.0032, 0.0036, 0.0024, 0.0016, 0.0025,\n",
            "         0.0028, 0.0063, 0.0057, 0.0024, 0.0090, 0.0043, 0.0043, 0.0083, 0.0043,\n",
            "         0.0061, 0.0025, 0.0039, 0.0034, 0.0062, 0.0086, 0.0045, 0.0021, 0.0029,\n",
            "         0.0051, 0.0022, 0.0046, 0.0033, 0.0032]], device='cuda:0',\n",
            "       grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-11e1958f7583>:113: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = self.fc1_activation(out)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#data\n",
        "# training_loader = DataLoader(TensorDataset(torch.tensor(X_train.transpose(0,3,1,2)), torch.tensor(y_train)), batch_size=5, pin_memory='True', pin_memory_device='cuda')\n",
        "# validation_loader = DataLoader(TensorDataset(torch.tensor(X_test.transpose(0,3,1,2)), torch.tensor(y_test)), batch_size=1, pin_memory='True', pin_memory_device='cuda')\n",
        "\n",
        "training_loader = DataLoader(TensorDataset(torch.tensor(X_train), torch.tensor(y_train)), batch_size=10, pin_memory='True', pin_memory_device='cuda', shuffle=True)\n",
        "validation_loader = DataLoader(TensorDataset(torch.tensor(X_test), torch.tensor(y_test)), batch_size=1, pin_memory='True', pin_memory_device='cuda')\n",
        "#loss function\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "# loss_fn = torch.nn.BCELoss()\n",
        "# loss_fn = torch.nn.BCEWithLogitsLoss()\n",
        "# Optimizers specified in the torch.optim package\n",
        "optimizer = torch.optim.Adam(pytorch_model_c1.parameters())\n",
        "\n",
        "# # import EarlyStopping\n",
        "# from pytorchtools import EarlyStopping"
      ],
      "metadata": {
        "id": "vGUNjmwkdwTG"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def to_categorical(y, num_classes):\n",
        "    \"\"\" 1-hot encodes a tensor \"\"\"\n",
        "    return np.eye(num_classes, dtype='uint8')[y]\n",
        "\n",
        "pytorch_model_c1 = Pytorch_BUS_Final_Model_C1().to(torch.device('cuda'))\n",
        "\n",
        "# manaul training\n",
        "def train_one_epoch():\n",
        "    # training metrics\n",
        "    train_loss = 0\n",
        "    train_correct = 0\n",
        "\n",
        "    # validation metrics\n",
        "    valid_loss = 0\n",
        "    valid_correct = 0\n",
        "\n",
        "\n",
        "    # Here, we use enumerate(training_loader) instead of\n",
        "    # iter(training_loader) so that we can track the batch\n",
        "    # index and do some intra-epoch reporting\n",
        "    pytorch_model_c1.train(True)\n",
        "    for i, data in enumerate(training_loader,0):\n",
        "        # Every data instance is an input + label pair\n",
        "        train_input, train_label = data\n",
        "        train_input = train_input.unsqueeze(dim=1).float()\n",
        "        train_label= torch.tensor(to_categorical(y=train_label, num_classes=221)).float()\n",
        "        # train_label = train_label[:,None]\n",
        "        if len(train_label.shape)==1:\n",
        "          train_label = train_label.unsqueeze(dim=0)\n",
        "\n",
        "        train_input = train_input.to(torch.device('cuda'))\n",
        "        train_label = train_label.to(torch.device('cuda'))\n",
        "\n",
        "        # print('train_input:',train_input.shape, 'train_label:',train_label.shape)\n",
        "\n",
        "        # Zero your gradients for every batch!\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Make predictions for this batch\n",
        "        train_output = pytorch_model_c1(train_input)\n",
        "        # print('train_input:',train_input.shape, 'train_label:',train_label.shape, 'train_output:',train_output.shape)\n",
        "        # print('train_label:',train_label)\n",
        "        # print('train_output:',train_output)\n",
        "\n",
        "        # Compute the loss and its gradients\n",
        "        loss = loss_fn(train_output, train_label)\n",
        "        loss.backward()\n",
        "\n",
        "        # Adjust learning weights\n",
        "        optimizer.step()\n",
        "\n",
        "        # Gather data and report\n",
        "        train_loss += loss.item()\n",
        "        for batch_count in range(train_output.shape[0]):\n",
        "          if(torch.argmax(train_output[batch_count,:]) == torch.argmax(train_label[batch_count,:])):\n",
        "            train_correct += 1\n",
        "\n",
        "    # print('training epoch complete')\n",
        "    # Here, we use enumerate(validation_loader) instead of\n",
        "    # iter(validation_loader) so that we can track the batch\n",
        "    # index and do some intra-epoch reporting\n",
        "    pytorch_model_c1.train(False)\n",
        "    for i, data in enumerate(validation_loader,0):\n",
        "        # Every data instance is an input + label pair\n",
        "        valid_input, valid_label = data\n",
        "\n",
        "        valid_input = valid_input.unsqueeze(dim=1).float()\n",
        "        valid_label= torch.tensor(to_categorical(y=valid_label, num_classes=221)).float()\n",
        "        if len(valid_label.shape)==1:\n",
        "          valid_label = valid_label.unsqueeze(dim=0)\n",
        "\n",
        "        valid_input = valid_input.to(torch.device('cuda'))\n",
        "        valid_label = valid_label.to(torch.device('cuda'))\n",
        "\n",
        "        # Make predictions for this batch\n",
        "        valid_output = pytorch_model_c1(valid_input)\n",
        "\n",
        "        # print('valid_input:',valid_input.shape, 'valid_label:',valid_label.shape, 'valid_output:',valid_output.shape)\n",
        "\n",
        "        # Gather data and report\n",
        "        valid_loss += loss_fn(valid_output, valid_label).item()\n",
        "        for batch_count in range(valid_output.shape[0]):\n",
        "          if(torch.argmax(valid_output[batch_count,:]) == torch.argmax(valid_label[batch_count,:])):\n",
        "            valid_correct += 1\n",
        "\n",
        "    print(f\"Training: \\n Training Accuracy: {100*train_correct/len(training_loader.dataset)}%, Average Training Loss: {train_loss/len(training_loader)} \\n\")\n",
        "\n",
        "    print(f\"Validation: \\n Validation Accuracy: {100*valid_correct/len(validation_loader.dataset)}%, Average Validation Loss: {valid_loss/len(validation_loader)} \\n\")\n",
        "\n",
        "    return train_loss, valid_loss\n"
      ],
      "metadata": {
        "id": "egUMDCzvdHRC"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def early_stopping(train_loss, validation_loss, min_delta, tolerance):\n",
        "\n",
        "#     counter = 0\n",
        "#     if (validation_loss - train_loss) > min_delta:\n",
        "#         counter +=1\n",
        "#         if counter >= tolerance:\n",
        "#           return True\n",
        "\n",
        "# early_stopping = EarlyStopping(patience=10, verbose=True)\n",
        "\n",
        "# Initializing in a separate cell so we can easily add more epochs to the same run\n",
        "epoch_number = 0\n",
        "EPOCHS = 100\n",
        "optimizer = torch.optim.Adam(pytorch_model_c1.parameters(), lr=1e-4)\n",
        "for epoch in range(EPOCHS):\n",
        "    print('EPOCH {}:'.format(epoch_number + 1))\n",
        "    train_loss, valid_loss = train_one_epoch()\n",
        "    # if early_stopping.early_stop:\n",
        "    #     print(\"Early stopping\")\n",
        "    #     break\n",
        "    # early stopping\n",
        "    # if early_stopping(train_loss, valid_loss, min_delta=10, tolerance = 20):\n",
        "    #   print(\"We are at epoch:\", epoch_number)\n",
        "    #   break\n",
        "    epoch_number += 1"
      ],
      "metadata": {
        "id": "MyKfEMIfd1FY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecab4e87-d038-4c4e-cd84-06e5affffd55"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-11e1958f7583>:113: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = self.fc1_activation(out)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH 1:\n",
            "Training: \n",
            " Training Accuracy: 1.2244897959183674%, Average Training Loss: 5.397762142882055 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 8.58085808580858%, Average Validation Loss: 5.393167508317299 \n",
            "\n",
            "EPOCH 2:\n",
            "Training: \n",
            " Training Accuracy: 7.551020408163265%, Average Training Loss: 5.388192079505142 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 4.9504950495049505%, Average Validation Loss: 5.378385812929361 \n",
            "\n",
            "EPOCH 3:\n",
            "Training: \n",
            " Training Accuracy: 8.979591836734693%, Average Training Loss: 5.362549810993428 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 6.600660066006601%, Average Validation Loss: 5.3450291778388195 \n",
            "\n",
            "EPOCH 4:\n",
            "Training: \n",
            " Training Accuracy: 12.653061224489797%, Average Training Loss: 5.3267148854781174 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 12.211221122112212%, Average Validation Loss: 5.3168719467943655 \n",
            "\n",
            "EPOCH 5:\n",
            "Training: \n",
            " Training Accuracy: 20.0%, Average Training Loss: 5.262342034553995 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 18.48184818481848%, Average Validation Loss: 5.28221857901847 \n",
            "\n",
            "EPOCH 6:\n",
            "Training: \n",
            " Training Accuracy: 32.04081632653061%, Average Training Loss: 5.1833945001874655 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 27.722772277227723%, Average Validation Loss: 5.214271161422477 \n",
            "\n",
            "EPOCH 7:\n",
            "Training: \n",
            " Training Accuracy: 43.265306122448976%, Average Training Loss: 5.083556652069092 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 39.93399339933993%, Average Validation Loss: 5.122630020179371 \n",
            "\n",
            "EPOCH 8:\n",
            "Training: \n",
            " Training Accuracy: 52.44897959183673%, Average Training Loss: 4.979784138348638 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 46.53465346534654%, Average Validation Loss: 5.116570982602563 \n",
            "\n",
            "EPOCH 9:\n",
            "Training: \n",
            " Training Accuracy: 60.40816326530612%, Average Training Loss: 4.895363155676394 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 54.12541254125413%, Average Validation Loss: 5.044862367925864 \n",
            "\n",
            "EPOCH 10:\n",
            "Training: \n",
            " Training Accuracy: 71.42857142857143%, Average Training Loss: 4.806598799569266 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 65.01650165016501%, Average Validation Loss: 4.961357477081098 \n",
            "\n",
            "EPOCH 11:\n",
            "Training: \n",
            " Training Accuracy: 79.38775510204081%, Average Training Loss: 4.716536658150809 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 70.62706270627062%, Average Validation Loss: 4.9151002817814895 \n",
            "\n",
            "EPOCH 12:\n",
            "Training: \n",
            " Training Accuracy: 85.51020408163265%, Average Training Loss: 4.637131827218192 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 77.55775577557756%, Average Validation Loss: 4.831723721507359 \n",
            "\n",
            "EPOCH 13:\n",
            "Training: \n",
            " Training Accuracy: 90.81632653061224%, Average Training Loss: 4.560868136736811 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 84.48844884488449%, Average Validation Loss: 4.790846393446718 \n",
            "\n",
            "EPOCH 14:\n",
            "Training: \n",
            " Training Accuracy: 94.89795918367346%, Average Training Loss: 4.52307653427124 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 84.48844884488449%, Average Validation Loss: 4.7674135721162605 \n",
            "\n",
            "EPOCH 15:\n",
            "Training: \n",
            " Training Accuracy: 96.73469387755102%, Average Training Loss: 4.484212048199712 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 88.11881188118812%, Average Validation Loss: 4.718455678165549 \n",
            "\n",
            "EPOCH 16:\n",
            "Training: \n",
            " Training Accuracy: 97.34693877551021%, Average Training Loss: 4.460999440173714 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 86.79867986798679%, Average Validation Loss: 4.705353791957641 \n",
            "\n",
            "EPOCH 17:\n",
            "Training: \n",
            " Training Accuracy: 98.36734693877551%, Average Training Loss: 4.449330563447913 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 86.79867986798679%, Average Validation Loss: 4.6785016248721885 \n",
            "\n",
            "EPOCH 18:\n",
            "Training: \n",
            " Training Accuracy: 98.9795918367347%, Average Training Loss: 4.437752616648772 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 88.44884488448845%, Average Validation Loss: 4.681131729591797 \n",
            "\n",
            "EPOCH 19:\n",
            "Training: \n",
            " Training Accuracy: 98.9795918367347%, Average Training Loss: 4.427952630179269 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 86.13861386138613%, Average Validation Loss: 4.685169268756023 \n",
            "\n",
            "EPOCH 20:\n",
            "Training: \n",
            " Training Accuracy: 98.9795918367347%, Average Training Loss: 4.42507774975835 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 89.10891089108911%, Average Validation Loss: 4.651341233709858 \n",
            "\n",
            "EPOCH 21:\n",
            "Training: \n",
            " Training Accuracy: 98.9795918367347%, Average Training Loss: 4.42407040693322 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 88.44884488448845%, Average Validation Loss: 4.6519075352760035 \n",
            "\n",
            "EPOCH 22:\n",
            "Training: \n",
            " Training Accuracy: 99.18367346938776%, Average Training Loss: 4.422766043215382 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 87.7887788778878%, Average Validation Loss: 4.675212299863104 \n",
            "\n",
            "EPOCH 23:\n",
            "Training: \n",
            " Training Accuracy: 99.59183673469387%, Average Training Loss: 4.419338226318359 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 89.10891089108911%, Average Validation Loss: 4.643051638461576 \n",
            "\n",
            "EPOCH 24:\n",
            "Training: \n",
            " Training Accuracy: 99.18367346938776%, Average Training Loss: 4.419612154668691 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 88.77887788778878%, Average Validation Loss: 4.646485498636076 \n",
            "\n",
            "EPOCH 25:\n",
            "Training: \n",
            " Training Accuracy: 99.38775510204081%, Average Training Loss: 4.417164325714111 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 90.0990099009901%, Average Validation Loss: 4.652596322616728 \n",
            "\n",
            "EPOCH 26:\n",
            "Training: \n",
            " Training Accuracy: 99.59183673469387%, Average Training Loss: 4.413984522527578 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 86.79867986798679%, Average Validation Loss: 4.660408076673451 \n",
            "\n",
            "EPOCH 27:\n",
            "Training: \n",
            " Training Accuracy: 99.59183673469387%, Average Training Loss: 4.414959528008286 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 86.46864686468646%, Average Validation Loss: 4.672455166039294 \n",
            "\n",
            "EPOCH 28:\n",
            "Training: \n",
            " Training Accuracy: 99.59183673469387%, Average Training Loss: 4.4135874534139825 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 90.75907590759076%, Average Validation Loss: 4.635967323882352 \n",
            "\n",
            "EPOCH 29:\n",
            "Training: \n",
            " Training Accuracy: 99.59183673469387%, Average Training Loss: 4.413062017791125 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 89.43894389438944%, Average Validation Loss: 4.619905975392156 \n",
            "\n",
            "EPOCH 30:\n",
            "Training: \n",
            " Training Accuracy: 99.59183673469387%, Average Training Loss: 4.413679502448257 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 89.43894389438944%, Average Validation Loss: 4.614081053843986 \n",
            "\n",
            "EPOCH 31:\n",
            "Training: \n",
            " Training Accuracy: 99.59183673469387%, Average Training Loss: 4.41273155990912 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 89.76897689768977%, Average Validation Loss: 4.6227433657882235 \n",
            "\n",
            "EPOCH 32:\n",
            "Training: \n",
            " Training Accuracy: 99.59183673469387%, Average Training Loss: 4.412341244366704 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 91.08910891089108%, Average Validation Loss: 4.617948673739292 \n",
            "\n",
            "EPOCH 33:\n",
            "Training: \n",
            " Training Accuracy: 99.59183673469387%, Average Training Loss: 4.412033304876211 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 87.45874587458746%, Average Validation Loss: 4.641601113989802 \n",
            "\n",
            "EPOCH 34:\n",
            "Training: \n",
            " Training Accuracy: 99.59183673469387%, Average Training Loss: 4.412712097167969 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 89.10891089108911%, Average Validation Loss: 4.612979283033818 \n",
            "\n",
            "EPOCH 35:\n",
            "Training: \n",
            " Training Accuracy: 99.59183673469387%, Average Training Loss: 4.41208418048158 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 88.77887788778878%, Average Validation Loss: 4.621224014672509 \n",
            "\n",
            "EPOCH 36:\n",
            "Training: \n",
            " Training Accuracy: 99.59183673469387%, Average Training Loss: 4.411607246009671 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 88.44884488448845%, Average Validation Loss: 4.624426583645761 \n",
            "\n",
            "EPOCH 37:\n",
            "Training: \n",
            " Training Accuracy: 99.59183673469387%, Average Training Loss: 4.4114059039524625 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 89.76897689768977%, Average Validation Loss: 4.629871941242281 \n",
            "\n",
            "EPOCH 38:\n",
            "Training: \n",
            " Training Accuracy: 99.59183673469387%, Average Training Loss: 4.411767424369345 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 89.43894389438944%, Average Validation Loss: 4.607824852757721 \n",
            "\n",
            "EPOCH 39:\n",
            "Training: \n",
            " Training Accuracy: 99.59183673469387%, Average Training Loss: 4.411627467797727 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 88.11881188118812%, Average Validation Loss: 4.627512607637412 \n",
            "\n",
            "EPOCH 40:\n",
            "Training: \n",
            " Training Accuracy: 99.59183673469387%, Average Training Loss: 4.411376262197689 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 87.45874587458746%, Average Validation Loss: 4.618420818064473 \n",
            "\n",
            "EPOCH 41:\n",
            "Training: \n",
            " Training Accuracy: 99.59183673469387%, Average Training Loss: 4.4114459582737515 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 89.43894389438944%, Average Validation Loss: 4.605107532476041 \n",
            "\n",
            "EPOCH 42:\n",
            "Training: \n",
            " Training Accuracy: 99.59183673469387%, Average Training Loss: 4.411751698474495 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 89.76897689768977%, Average Validation Loss: 4.614686013841786 \n",
            "\n",
            "EPOCH 43:\n",
            "Training: \n",
            " Training Accuracy: 99.59183673469387%, Average Training Loss: 4.411246951745481 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 89.76897689768977%, Average Validation Loss: 4.605169485111047 \n",
            "\n",
            "EPOCH 44:\n",
            "Training: \n",
            " Training Accuracy: 99.59183673469387%, Average Training Loss: 4.411190188660914 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 88.77887788778878%, Average Validation Loss: 4.590652166813514 \n",
            "\n",
            "EPOCH 45:\n",
            "Training: \n",
            " Training Accuracy: 99.59183673469387%, Average Training Loss: 4.4109766337336325 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 88.44884488448845%, Average Validation Loss: 4.611316030961846 \n",
            "\n",
            "EPOCH 46:\n",
            "Training: \n",
            " Training Accuracy: 99.59183673469387%, Average Training Loss: 4.410924035675672 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 88.77887788778878%, Average Validation Loss: 4.614005549906111 \n",
            "\n",
            "EPOCH 47:\n",
            "Training: \n",
            " Training Accuracy: 99.59183673469387%, Average Training Loss: 4.410903453826904 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 86.13861386138613%, Average Validation Loss: 4.634997306483807 \n",
            "\n",
            "EPOCH 48:\n",
            "Training: \n",
            " Training Accuracy: 99.59183673469387%, Average Training Loss: 4.411080156053815 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 88.77887788778878%, Average Validation Loss: 4.599370717215459 \n",
            "\n",
            "EPOCH 49:\n",
            "Training: \n",
            " Training Accuracy: 99.59183673469387%, Average Training Loss: 4.411479375800308 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 89.43894389438944%, Average Validation Loss: 4.632797691294856 \n",
            "\n",
            "EPOCH 50:\n",
            "Training: \n",
            " Training Accuracy: 99.59183673469387%, Average Training Loss: 4.410928823509995 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 89.76897689768977%, Average Validation Loss: 4.612143909970526 \n",
            "\n",
            "EPOCH 51:\n",
            "Training: \n",
            " Training Accuracy: 99.38775510204081%, Average Training Loss: 4.412451481332584 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 87.12871287128714%, Average Validation Loss: 4.683412652597962 \n",
            "\n",
            "EPOCH 52:\n",
            "Training: \n",
            " Training Accuracy: 99.79591836734694%, Average Training Loss: 4.410072920273762 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 89.10891089108911%, Average Validation Loss: 4.618456297581739 \n",
            "\n",
            "EPOCH 53:\n",
            "Training: \n",
            " Training Accuracy: 99.38775510204081%, Average Training Loss: 4.413053843439842 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 88.77887788778878%, Average Validation Loss: 4.613746062363728 \n",
            "\n",
            "EPOCH 54:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.408403279829998 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 90.42904290429043%, Average Validation Loss: 4.608697875498152 \n",
            "\n",
            "EPOCH 55:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.408376518560916 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 89.43894389438944%, Average Validation Loss: 4.601648884637915 \n",
            "\n",
            "EPOCH 56:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.406925288998351 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 90.0990099009901%, Average Validation Loss: 4.603180098454945 \n",
            "\n",
            "EPOCH 57:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.406760643939583 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 90.75907590759076%, Average Validation Loss: 4.590745002129684 \n",
            "\n",
            "EPOCH 58:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.40664308898303 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 89.76897689768977%, Average Validation Loss: 4.586784765665287 \n",
            "\n",
            "EPOCH 59:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.406660225926613 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 89.43894389438944%, Average Validation Loss: 4.595078602088954 \n",
            "\n",
            "EPOCH 60:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.406538019374925 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 89.76897689768977%, Average Validation Loss: 4.621112149934171 \n",
            "\n",
            "EPOCH 61:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.406400563765545 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 89.76897689768977%, Average Validation Loss: 4.585970301045837 \n",
            "\n",
            "EPOCH 62:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.406450456502486 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 90.42904290429043%, Average Validation Loss: 4.586771333965138 \n",
            "\n",
            "EPOCH 63:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.406509156129798 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 90.0990099009901%, Average Validation Loss: 4.61673636483674 \n",
            "\n",
            "EPOCH 64:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.4064342537704775 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 90.0990099009901%, Average Validation Loss: 4.585416737169322 \n",
            "\n",
            "EPOCH 65:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.406423014037463 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 90.42904290429043%, Average Validation Loss: 4.575507288325344 \n",
            "\n",
            "EPOCH 66:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.406318742401746 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 90.42904290429043%, Average Validation Loss: 4.578350990912308 \n",
            "\n",
            "EPOCH 67:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.406323403728251 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 90.42904290429043%, Average Validation Loss: 4.583757526410295 \n",
            "\n",
            "EPOCH 68:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.4064212818535005 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 88.44884488448845%, Average Validation Loss: 4.59980583977778 \n",
            "\n",
            "EPOCH 69:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.406275398877202 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 89.76897689768977%, Average Validation Loss: 4.574113825366835 \n",
            "\n",
            "EPOCH 70:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.406259273996159 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 90.0990099009901%, Average Validation Loss: 4.575469259381688 \n",
            "\n",
            "EPOCH 71:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.406234750942308 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 91.08910891089108%, Average Validation Loss: 4.575751068568466 \n",
            "\n",
            "EPOCH 72:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.40624594201847 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 90.0990099009901%, Average Validation Loss: 4.573744089296548 \n",
            "\n",
            "EPOCH 73:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.406232094278141 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 88.77887788778878%, Average Validation Loss: 4.594345959893154 \n",
            "\n",
            "EPOCH 74:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.4062078826281486 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 90.0990099009901%, Average Validation Loss: 4.577230209564612 \n",
            "\n",
            "EPOCH 75:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.406201430729458 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 91.08910891089108%, Average Validation Loss: 4.573243781678354 \n",
            "\n",
            "EPOCH 76:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.406221068635279 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 90.42904290429043%, Average Validation Loss: 4.564131546335251 \n",
            "\n",
            "EPOCH 77:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.406166183705232 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 90.42904290429043%, Average Validation Loss: 4.569995261654995 \n",
            "\n",
            "EPOCH 78:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.406205508173729 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 90.42904290429043%, Average Validation Loss: 4.577676957196529 \n",
            "\n",
            "EPOCH 79:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.406220523678527 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 90.0990099009901%, Average Validation Loss: 4.570763170915861 \n",
            "\n",
            "EPOCH 80:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.406190025563142 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 90.0990099009901%, Average Validation Loss: 4.5740190213269525 \n",
            "\n",
            "EPOCH 81:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.406187495406793 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 88.44884488448845%, Average Validation Loss: 4.5744694278578555 \n",
            "\n",
            "EPOCH 82:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.406156754007145 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 90.42904290429043%, Average Validation Loss: 4.574913053229304 \n",
            "\n",
            "EPOCH 83:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.406141767696458 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 91.08910891089108%, Average Validation Loss: 4.569421645438317 \n",
            "\n",
            "EPOCH 84:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.406151888321857 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 89.76897689768977%, Average Validation Loss: 4.5774500330682635 \n",
            "\n",
            "EPOCH 85:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.406154963434959 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 90.42904290429043%, Average Validation Loss: 4.56914486428692 \n",
            "\n",
            "EPOCH 86:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.406147752489362 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 91.74917491749174%, Average Validation Loss: 4.5743833343581395 \n",
            "\n",
            "EPOCH 87:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.4061139749020946 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 90.0990099009901%, Average Validation Loss: 4.568316664239361 \n",
            "\n",
            "EPOCH 88:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.40612929207938 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 88.77887788778878%, Average Validation Loss: 4.576425610595804 \n",
            "\n",
            "EPOCH 89:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.406097256407445 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 88.11881188118812%, Average Validation Loss: 4.583952820340399 \n",
            "\n",
            "EPOCH 90:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.406085851241131 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 91.08910891089108%, Average Validation Loss: 4.562745423206795 \n",
            "\n",
            "EPOCH 91:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.406090541761749 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 90.75907590759076%, Average Validation Loss: 4.5695061290224785 \n",
            "\n",
            "EPOCH 92:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.406083943892498 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 90.75907590759076%, Average Validation Loss: 4.570193430771528 \n",
            "\n",
            "EPOCH 93:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.406103455290502 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 90.0990099009901%, Average Validation Loss: 4.585880565958054 \n",
            "\n",
            "EPOCH 94:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.406060024183624 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 90.75907590759076%, Average Validation Loss: 4.5708381649684595 \n",
            "\n",
            "EPOCH 95:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.406069395493488 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 90.42904290429043%, Average Validation Loss: 4.573371805373592 \n",
            "\n",
            "EPOCH 96:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.406064160016118 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 89.76897689768977%, Average Validation Loss: 4.571768593866833 \n",
            "\n",
            "EPOCH 97:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.406065308317846 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 88.77887788778878%, Average Validation Loss: 4.5831716666520625 \n",
            "\n",
            "EPOCH 98:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.40606301171439 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 90.75907590759076%, Average Validation Loss: 4.56529683091066 \n",
            "\n",
            "EPOCH 99:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.406044278826032 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 88.77887788778878%, Average Validation Loss: 4.589833711240158 \n",
            "\n",
            "EPOCH 100:\n",
            "Training: \n",
            " Training Accuracy: 100.0%, Average Training Loss: 4.406068120683942 \n",
            "\n",
            "Validation: \n",
            " Validation Accuracy: 90.0990099009901%, Average Validation Loss: 4.571996416589214 \n",
            "\n"
          ]
        }
      ]
    }
  ]
}