{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IITD-Dataset-CustomModel(Paper)_EarBiometrics.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shujaat123/Ear_Biometrics/blob/main/IITD_Dataset_CustomModel(Paper)_EarBiometrics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GoJ8BY9Tb_qb",
        "outputId": "481c6d08-f39a-4830-ccbb-fb2edf832e88"
      },
      "source": [
        "## Load useful packages\n",
        "!pip install wget\n",
        "!pip install py7zr\n",
        "\n",
        "import keras\n",
        "import py7zr\n",
        "from zipfile import ZipFile\n",
        "from random import sample\n",
        "\n",
        "import PIL.Image as Image\n",
        "from scipy import io\n",
        "import matplotlib.pyplot as plt\n",
        "from  sklearn.model_selection import train_test_split\n",
        "from os import listdir\n",
        "from os import path\n",
        "import h5py\n",
        "import keras.backend as K\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import wget\n",
        "from keras import regularizers\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.layers import *\n",
        "from keras.models import Model\n",
        "from keras.models import load_model\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp37-none-any.whl size=9675 sha256=77e2cc07d99dc6db40aeb98fb2b3361f38bd7c68b1e15fffc153dc0faaa19b6e\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n",
            "Collecting py7zr\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/db/1c/d3e3a80fa8901fc232ec11ec0f2886c7e06cf38f3f40876438ada5659211/py7zr-0.16.1-py3-none-any.whl (65kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 8.4MB/s \n",
            "\u001b[?25hCollecting bcj-cffi<0.6.0,>=0.5.1\n",
            "  Downloading https://files.pythonhosted.org/packages/ab/1f/408e7b01375c863e01c25b1475d628deab7c9f85aeb74cced4caa5a512ce/bcj_cffi-0.5.1-cp37-cp37m-manylinux2014_x86_64.whl\n",
            "Collecting texttable\n",
            "  Downloading https://files.pythonhosted.org/packages/75/23/8170868d04b153b1b9ed1bb84348212bb4a08f31b292ef9d7f6ea648fd49/texttable-1.6.4-py2.py3-none-any.whl\n",
            "Collecting brotli>=1.0.9; platform_python_implementation == \"CPython\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/ea/5bd575511b37bbd1c794606a0a621e6feff8e96b7dd007a86a5d218b2d94/Brotli-1.0.9-cp37-cp37m-manylinux1_x86_64.whl (357kB)\n",
            "\u001b[K     |████████████████████████████████| 358kB 34.1MB/s \n",
            "\u001b[?25hCollecting pycryptodomex>=3.6.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/9d/99a949925b5fc9604cb65219951fd270ef30d0fd4f064d1b363eb8bb5e9b/pycryptodomex-3.10.1-cp35-abi3-manylinux2010_x86_64.whl (1.9MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9MB 47.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from py7zr) (4.6.0)\n",
            "Collecting pyppmd>=0.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/ef/4a44ba307d8440b135ea9096a0e91cd11a04c91f6bce6eb7c6eba7e95ba6/pyppmd-0.15.1-cp37-cp37m-manylinux2014_x86_64.whl (121kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 51.0MB/s \n",
            "\u001b[?25hCollecting pyzstd<0.15.0,>=0.14.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/e9/fe897f8bb96163645a5b2d3a60ff8bfa6fcdedff4691a3c6c861b0324ef4/pyzstd-0.14.4-cp37-cp37m-manylinux2014_x86_64.whl (2.2MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2MB 49.6MB/s \n",
            "\u001b[?25hCollecting multivolumefile>=0.2.3\n",
            "  Downloading https://files.pythonhosted.org/packages/22/31/ec5f46fd4c83185b806aa9c736e228cb780f13990a9cf4da0beb70025fcc/multivolumefile-0.2.3-py3-none-any.whl\n",
            "Requirement already satisfied: cffi>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from bcj-cffi<0.6.0,>=0.5.1->py7zr) (1.14.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->py7zr) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->py7zr) (3.7.4.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.14.0->bcj-cffi<0.6.0,>=0.5.1->py7zr) (2.20)\n",
            "Installing collected packages: bcj-cffi, texttable, brotli, pycryptodomex, pyppmd, pyzstd, multivolumefile, py7zr\n",
            "Successfully installed bcj-cffi-0.5.1 brotli-1.0.9 multivolumefile-0.2.3 py7zr-0.16.1 pycryptodomex-3.10.1 pyppmd-0.15.1 pyzstd-0.14.4 texttable-1.6.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4NI4AmSEfuKC",
        "outputId": "8e223f3e-261d-4715-9789-a34839dac012"
      },
      "source": [
        "data_path = 'https://github.com/Alishba18001778/EarClassification/blob/main/IITD_Data_Tensor.mat?raw=true'\n",
        "Data_filename = 'IITD_Data_Tensor.mat'\n",
        "\n",
        "data_path_labels = 'https://github.com/Alishba18001778/EarClassification/blob/main/IITD_Labels.mat?raw=true'\n",
        "labels_filename = 'IITD_Labels.mat'\n",
        "\n",
        "if(path.exists(labels_filename)):\n",
        "  !rm $labels_filename\n",
        "  print('existing file:', labels_filename, ' has been deleted')\n",
        "print('downloading latest version of file:', labels_filename)\n",
        "wget.download(data_path_labels, labels_filename)\n",
        "\n",
        "if(path.exists(Data_filename)):\n",
        "  !rm $Data_filename\n",
        "  print('existing file:', Data_filename, ' has been deleted')\n",
        "print('downloading latest version of file:', Data_filename)\n",
        "wget.download(data_path, Data_filename)\n",
        "# \n",
        "u = io.loadmat('IITD_Data_Tensor.mat')\n",
        "v = io.loadmat('IITD_Labels.mat')\n",
        "sub_labels = v[\"sub_labels\"]\n",
        "sub_labels = np.squeeze(sub_labels.transpose())\n",
        "ear_images = u[\"ear_images\"]\n",
        "ear_images = np.array(ear_images)\n",
        "\n",
        "# sub_labels = to_categorical(np.array(sub_labels))\n",
        "print(ear_images.shape)\n",
        "print(sub_labels.shape)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "existing file: IITD_Labels.mat  has been deleted\n",
            "downloading latest version of file: IITD_Labels.mat\n",
            "existing file: IITD_Data_Tensor.mat  has been deleted\n",
            "downloading latest version of file: IITD_Data_Tensor.mat\n",
            "(793, 180, 50)\n",
            "(793,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6f9PJYHn1St",
        "outputId": "d40537c9-a65c-4ba3-93b1-ce64c0712471"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(ear_images, sub_labels, test_size=0.382093316519, stratify=sub_labels, random_state=42)\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(490, 180, 50)\n",
            "(490,)\n",
            "(303, 180, 50)\n",
            "(303,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMayf8bT3F_m"
      },
      "source": [
        "### Write Augmentation code here\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTzprQ3t3giN",
        "outputId": "0692e883-ca30-40a4-84d1-7795dfddca08"
      },
      "source": [
        "#Custom Model\n",
        "\n",
        "def new_model():\n",
        "  input_img = Input(shape=(180,50, 1))\n",
        "  num_filter = 8\n",
        "  kernel_size = 3\n",
        "  strides = 1\n",
        "  \n",
        "  x = Conv2D(num_filter, kernel_size, strides, activation='relu',padding = 'same', name = 'enc1')(input_img)\n",
        "  x = MaxPool2D((2, 2))(x)\n",
        "\n",
        "    \n",
        "  x = Conv2D(2*num_filter, kernel_size, strides, activation='relu', padding = 'same', name = 'enc3')(x) \n",
        "  x = BatchNormalization()(x)\n",
        "  x = MaxPool2D((2, 2))(x)   \n",
        " \n",
        "    \n",
        "  x = Conv2D(4*num_filter, kernel_size, strides, activation='relu', padding = 'same', name = 'enc4')(x) \n",
        "  x = MaxPool2D((2, 2))(x) \n",
        "\n",
        "  x = Conv2D(8*num_filter, kernel_size, strides, activation='relu', padding = 'same', name = 'enc5')(x) \n",
        "  x = BatchNormalization()(x)\n",
        "  x = MaxPool2D((2, 2))(x) \n",
        "  \n",
        "  x = Conv2D(16*num_filter, kernel_size, strides, activation='relu', padding = 'same', name = 'enc6')(x) \n",
        "  x = MaxPool2D((2, 2))(x) \n",
        "\n",
        "  \n",
        "  x = Conv2D(32*num_filter, kernel_size, strides, activation='relu', padding = 'same', name = 'enc7')(x) \n",
        "  x = BatchNormalization()(x)\n",
        "\n",
        "  y = Flatten()(x) \n",
        "\n",
        "  output = Dense(221, activation='softmax')(y)\n",
        "\n",
        "  Arch_pre = Model(input_img, output)\n",
        "  \n",
        "  Arch_pre.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "                loss=keras.losses.SparseCategoricalCrossentropy(),\n",
        "                metrics=['accuracy'])\n",
        "  return Arch_pre\n",
        "\n",
        "Arch_pre= new_model()\n",
        "Arch_pre.summary()"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_15\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_20 (InputLayer)        [(None, 180, 50, 1)]      0         \n",
            "_________________________________________________________________\n",
            "enc1 (Conv2D)                (None, 180, 50, 8)        80        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_95 (MaxPooling (None, 90, 25, 8)         0         \n",
            "_________________________________________________________________\n",
            "enc3 (Conv2D)                (None, 90, 25, 16)        1168      \n",
            "_________________________________________________________________\n",
            "batch_normalization_61 (Batc (None, 90, 25, 16)        64        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_96 (MaxPooling (None, 45, 12, 16)        0         \n",
            "_________________________________________________________________\n",
            "enc4 (Conv2D)                (None, 45, 12, 32)        4640      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_97 (MaxPooling (None, 22, 6, 32)         0         \n",
            "_________________________________________________________________\n",
            "enc5 (Conv2D)                (None, 22, 6, 64)         18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_62 (Batc (None, 22, 6, 64)         256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_98 (MaxPooling (None, 11, 3, 64)         0         \n",
            "_________________________________________________________________\n",
            "enc6 (Conv2D)                (None, 11, 3, 128)        73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_99 (MaxPooling (None, 5, 1, 128)         0         \n",
            "_________________________________________________________________\n",
            "enc7 (Conv2D)                (None, 5, 1, 256)         295168    \n",
            "_________________________________________________________________\n",
            "batch_normalization_63 (Batc (None, 5, 1, 256)         1024      \n",
            "_________________________________________________________________\n",
            "flatten_19 (Flatten)         (None, 1280)              0         \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 221)               283101    \n",
            "=================================================================\n",
            "Total params: 677,853\n",
            "Trainable params: 677,181\n",
            "Non-trainable params: 672\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EBTVJNSM4MDH",
        "outputId": "85f48780-5528-4477-f19f-8b55b04cbaca"
      },
      "source": [
        "Arch_pre= new_model()\n",
        "#Using the best model \n",
        "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=100, mode='min')\n",
        "\n",
        "checkpoint = ModelCheckpoint('models\\\\modelweather-best.h5',\n",
        "                                  verbose=0, monitor='val_loss',save_best_only=True, mode='auto')\n",
        "\n",
        "Arch_pre.fit(X_train, y_train,\n",
        "                epochs=100,\n",
        "                batch_size=5,\n",
        "                shuffle=True,\n",
        "                validation_data=(X_test, y_test),\n",
        "                callbacks = [es, checkpoint]\n",
        "                )\n",
        "\n",
        "del Arch_pre  # deletes the existing model\n",
        "Arch_pre = load_model('models\\\\modelweather-best.h5')"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "98/98 [==============================] - 3s 13ms/step - loss: 6.4293 - accuracy: 0.0112 - val_loss: 5.6007 - val_accuracy: 0.0132\n",
            "Epoch 2/100\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 5.0741 - accuracy: 0.0628 - val_loss: 6.6437 - val_accuracy: 0.0066\n",
            "Epoch 3/100\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 3.3353 - accuracy: 0.2639 - val_loss: 6.3175 - val_accuracy: 0.0066\n",
            "Epoch 4/100\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 1.5159 - accuracy: 0.6590 - val_loss: 5.5703 - val_accuracy: 0.0066\n",
            "Epoch 5/100\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.4649 - accuracy: 0.9116 - val_loss: 2.0347 - val_accuracy: 0.5413\n",
            "Epoch 6/100\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.1573 - accuracy: 0.9730 - val_loss: 1.6278 - val_accuracy: 0.6007\n",
            "Epoch 7/100\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0533 - accuracy: 0.9891 - val_loss: 1.5154 - val_accuracy: 0.6733\n",
            "Epoch 8/100\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0455 - accuracy: 0.9980 - val_loss: 0.7508 - val_accuracy: 0.8581\n",
            "Epoch 9/100\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.5064 - val_accuracy: 0.8977\n",
            "Epoch 10/100\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.4385 - val_accuracy: 0.8944\n",
            "Epoch 11/100\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.4146 - val_accuracy: 0.9010\n",
            "Epoch 12/100\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.4317 - val_accuracy: 0.9010\n",
            "Epoch 13/100\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.4073 - val_accuracy: 0.8977\n",
            "Epoch 14/100\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.4024 - val_accuracy: 0.9010\n",
            "Epoch 15/100\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.3973 - val_accuracy: 0.9076\n",
            "Epoch 16/100\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.3901 - val_accuracy: 0.9109\n",
            "Epoch 17/100\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.3889 - val_accuracy: 0.9043\n",
            "Epoch 18/100\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3902 - val_accuracy: 0.9043\n",
            "Epoch 19/100\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3811 - val_accuracy: 0.9076\n",
            "Epoch 20/100\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3843 - val_accuracy: 0.8944\n",
            "Epoch 21/100\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3798 - val_accuracy: 0.8944\n",
            "Epoch 22/100\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3758 - val_accuracy: 0.9010\n",
            "Epoch 23/100\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3757 - val_accuracy: 0.8944\n",
            "Epoch 24/100\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3755 - val_accuracy: 0.9010\n",
            "Epoch 25/100\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 9.0935e-04 - accuracy: 1.0000 - val_loss: 0.3705 - val_accuracy: 0.9043\n",
            "Epoch 26/100\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 7.3532e-04 - accuracy: 1.0000 - val_loss: 0.3723 - val_accuracy: 0.9043\n",
            "Epoch 27/100\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 7.3999e-04 - accuracy: 1.0000 - val_loss: 0.3713 - val_accuracy: 0.9010\n",
            "Epoch 28/100\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 7.4566e-04 - accuracy: 1.0000 - val_loss: 0.3668 - val_accuracy: 0.9043\n",
            "Epoch 29/100\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 5.6063e-04 - accuracy: 1.0000 - val_loss: 0.3659 - val_accuracy: 0.9043\n",
            "Epoch 30/100\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 5.6848e-04 - accuracy: 1.0000 - val_loss: 0.3716 - val_accuracy: 0.9109\n",
            "Epoch 31/100\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 5.3108e-04 - accuracy: 1.0000 - val_loss: 0.3594 - val_accuracy: 0.9109\n",
            "Epoch 32/100\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 5.1140e-04 - accuracy: 1.0000 - val_loss: 0.3595 - val_accuracy: 0.9043\n",
            "Epoch 33/100\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 4.0277e-04 - accuracy: 1.0000 - val_loss: 0.3585 - val_accuracy: 0.9076\n",
            "Epoch 34/100\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 4.3566e-04 - accuracy: 1.0000 - val_loss: 0.3649 - val_accuracy: 0.9076\n",
            "Epoch 35/100\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 3.6538e-04 - accuracy: 1.0000 - val_loss: 0.3616 - val_accuracy: 0.9010\n",
            "Epoch 36/100\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 3.3564e-04 - accuracy: 1.0000 - val_loss: 0.3622 - val_accuracy: 0.9010\n",
            "Epoch 37/100\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 2.8283e-04 - accuracy: 1.0000 - val_loss: 0.3611 - val_accuracy: 0.8977\n",
            "Epoch 38/100\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 3.0136e-04 - accuracy: 1.0000 - val_loss: 0.3626 - val_accuracy: 0.9010\n",
            "Epoch 39/100\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 3.6094e-04 - accuracy: 1.0000 - val_loss: 0.3751 - val_accuracy: 0.8944\n",
            "Epoch 40/100\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 2.7051e-04 - accuracy: 1.0000 - val_loss: 0.3699 - val_accuracy: 0.9076\n",
            "Epoch 41/100\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 2.0709e-04 - accuracy: 1.0000 - val_loss: 0.3630 - val_accuracy: 0.9043\n",
            "Epoch 42/100\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 1.8678e-04 - accuracy: 1.0000 - val_loss: 0.3592 - val_accuracy: 0.9076\n",
            "Epoch 43/100\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 1.9648e-04 - accuracy: 1.0000 - val_loss: 0.3606 - val_accuracy: 0.9109\n",
            "Epoch 44/100\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.5086e-04 - accuracy: 1.0000 - val_loss: 0.3603 - val_accuracy: 0.9109\n",
            "Epoch 45/100\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 1.5987e-04 - accuracy: 1.0000 - val_loss: 0.3534 - val_accuracy: 0.9142\n",
            "Epoch 46/100\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 1.3857e-04 - accuracy: 1.0000 - val_loss: 0.3593 - val_accuracy: 0.9076\n",
            "Epoch 47/100\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 1.6268e-04 - accuracy: 1.0000 - val_loss: 0.3601 - val_accuracy: 0.9109\n",
            "Epoch 48/100\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 1.3586e-04 - accuracy: 1.0000 - val_loss: 0.3645 - val_accuracy: 0.9076\n",
            "Epoch 49/100\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 1.0193e-04 - accuracy: 1.0000 - val_loss: 0.3613 - val_accuracy: 0.9076\n",
            "Epoch 50/100\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 9.9247e-05 - accuracy: 1.0000 - val_loss: 0.3651 - val_accuracy: 0.9076\n",
            "Epoch 51/100\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 1.0906e-04 - accuracy: 1.0000 - val_loss: 0.3633 - val_accuracy: 0.9109\n",
            "Epoch 52/100\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 8.9766e-05 - accuracy: 1.0000 - val_loss: 0.3679 - val_accuracy: 0.9142\n",
            "Epoch 53/100\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 9.2959e-05 - accuracy: 1.0000 - val_loss: 0.3680 - val_accuracy: 0.9142\n",
            "Epoch 54/100\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 7.7787e-05 - accuracy: 1.0000 - val_loss: 0.3679 - val_accuracy: 0.9142\n",
            "Epoch 55/100\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 8.6552e-05 - accuracy: 1.0000 - val_loss: 0.3614 - val_accuracy: 0.9142\n",
            "Epoch 56/100\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 6.7483e-05 - accuracy: 1.0000 - val_loss: 0.3670 - val_accuracy: 0.9076\n",
            "Epoch 57/100\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 9.1520e-05 - accuracy: 1.0000 - val_loss: 0.3634 - val_accuracy: 0.9175\n",
            "Epoch 58/100\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 6.8234e-05 - accuracy: 1.0000 - val_loss: 0.3673 - val_accuracy: 0.9175\n",
            "Epoch 59/100\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 8.5973e-05 - accuracy: 1.0000 - val_loss: 0.3656 - val_accuracy: 0.9208\n",
            "Epoch 60/100\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 6.6893e-05 - accuracy: 1.0000 - val_loss: 0.3717 - val_accuracy: 0.9142\n",
            "Epoch 61/100\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 5.5099e-05 - accuracy: 1.0000 - val_loss: 0.3774 - val_accuracy: 0.9142\n",
            "Epoch 62/100\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 6.3992e-05 - accuracy: 1.0000 - val_loss: 0.3961 - val_accuracy: 0.9142\n",
            "Epoch 63/100\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 5.4820e-05 - accuracy: 1.0000 - val_loss: 0.3672 - val_accuracy: 0.9109\n",
            "Epoch 64/100\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 4.6288e-05 - accuracy: 1.0000 - val_loss: 0.3715 - val_accuracy: 0.9109\n",
            "Epoch 65/100\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 4.1510e-05 - accuracy: 1.0000 - val_loss: 0.3689 - val_accuracy: 0.9076\n",
            "Epoch 66/100\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 4.3016e-05 - accuracy: 1.0000 - val_loss: 0.3671 - val_accuracy: 0.9142\n",
            "Epoch 67/100\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 3.5783e-05 - accuracy: 1.0000 - val_loss: 0.3705 - val_accuracy: 0.9208\n",
            "Epoch 68/100\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 3.6944e-05 - accuracy: 1.0000 - val_loss: 0.3722 - val_accuracy: 0.9109\n",
            "Epoch 69/100\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 3.9247e-05 - accuracy: 1.0000 - val_loss: 0.3764 - val_accuracy: 0.9043\n",
            "Epoch 70/100\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 2.8452e-05 - accuracy: 1.0000 - val_loss: 0.3690 - val_accuracy: 0.9109\n",
            "Epoch 71/100\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 4.3353e-05 - accuracy: 1.0000 - val_loss: 0.3760 - val_accuracy: 0.9109\n",
            "Epoch 72/100\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 3.0926e-05 - accuracy: 1.0000 - val_loss: 0.3880 - val_accuracy: 0.9109\n",
            "Epoch 73/100\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 2.8514e-05 - accuracy: 1.0000 - val_loss: 0.3887 - val_accuracy: 0.9109\n",
            "Epoch 74/100\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 2.0446e-05 - accuracy: 1.0000 - val_loss: 0.3880 - val_accuracy: 0.9142\n",
            "Epoch 75/100\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 2.6775e-05 - accuracy: 1.0000 - val_loss: 0.3823 - val_accuracy: 0.9142\n",
            "Epoch 76/100\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 2.4292e-05 - accuracy: 1.0000 - val_loss: 0.3876 - val_accuracy: 0.9076\n",
            "Epoch 77/100\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 1.6700e-05 - accuracy: 1.0000 - val_loss: 0.3854 - val_accuracy: 0.9076\n",
            "Epoch 78/100\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 1.6865e-05 - accuracy: 1.0000 - val_loss: 0.3899 - val_accuracy: 0.9109\n",
            "Epoch 79/100\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 2.0624e-05 - accuracy: 1.0000 - val_loss: 0.3979 - val_accuracy: 0.9076\n",
            "Epoch 80/100\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 1.5255e-05 - accuracy: 1.0000 - val_loss: 0.3980 - val_accuracy: 0.9109\n",
            "Epoch 81/100\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 1.7006e-05 - accuracy: 1.0000 - val_loss: 0.3926 - val_accuracy: 0.9043\n",
            "Epoch 82/100\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 1.5907e-05 - accuracy: 1.0000 - val_loss: 0.3916 - val_accuracy: 0.9076\n",
            "Epoch 83/100\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 1.3020e-05 - accuracy: 1.0000 - val_loss: 0.3961 - val_accuracy: 0.9109\n",
            "Epoch 84/100\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 1.2802e-05 - accuracy: 1.0000 - val_loss: 0.4030 - val_accuracy: 0.9109\n",
            "Epoch 85/100\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 1.3300e-05 - accuracy: 1.0000 - val_loss: 0.3968 - val_accuracy: 0.9109\n",
            "Epoch 86/100\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 1.3161e-05 - accuracy: 1.0000 - val_loss: 0.4096 - val_accuracy: 0.9076\n",
            "Epoch 87/100\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 1.0591e-05 - accuracy: 1.0000 - val_loss: 0.4032 - val_accuracy: 0.9076\n",
            "Epoch 88/100\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 1.0099e-05 - accuracy: 1.0000 - val_loss: 0.4060 - val_accuracy: 0.9076\n",
            "Epoch 89/100\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 8.9006e-06 - accuracy: 1.0000 - val_loss: 0.4106 - val_accuracy: 0.9076\n",
            "Epoch 90/100\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 8.5203e-06 - accuracy: 1.0000 - val_loss: 0.4312 - val_accuracy: 0.9043\n",
            "Epoch 91/100\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 1.0241e-05 - accuracy: 1.0000 - val_loss: 0.4162 - val_accuracy: 0.9109\n",
            "Epoch 92/100\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 9.9683e-06 - accuracy: 1.0000 - val_loss: 0.4207 - val_accuracy: 0.9076\n",
            "Epoch 93/100\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 7.5838e-06 - accuracy: 1.0000 - val_loss: 0.4268 - val_accuracy: 0.9109\n",
            "Epoch 94/100\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 7.3731e-06 - accuracy: 1.0000 - val_loss: 0.4263 - val_accuracy: 0.9076\n",
            "Epoch 95/100\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 7.3028e-06 - accuracy: 1.0000 - val_loss: 0.4262 - val_accuracy: 0.9076\n",
            "Epoch 96/100\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 7.2556e-06 - accuracy: 1.0000 - val_loss: 0.4437 - val_accuracy: 0.9076\n",
            "Epoch 97/100\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 5.6939e-06 - accuracy: 1.0000 - val_loss: 0.4213 - val_accuracy: 0.9043\n",
            "Epoch 98/100\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 6.5220e-06 - accuracy: 1.0000 - val_loss: 0.4374 - val_accuracy: 0.9043\n",
            "Epoch 99/100\n",
            "98/98 [==============================] - 1s 9ms/step - loss: 5.3720e-06 - accuracy: 1.0000 - val_loss: 0.4436 - val_accuracy: 0.9076\n",
            "Epoch 100/100\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 5.8214e-06 - accuracy: 1.0000 - val_loss: 0.4348 - val_accuracy: 0.9043\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SX-mhHg4iZf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72d88f1e-7c03-4737-9298-8355925cc8a4"
      },
      "source": [
        "y_test_pred = Arch_pre.predict(X_test, batch_size=1, verbose=0)\n",
        "acc = accuracy_score(y_test, y_test_pred.argmax(axis=1))\n",
        "\n",
        "print('Test Accuracy: \\t',acc)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy: \t 0.9141914191419142\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}